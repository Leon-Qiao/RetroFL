{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcb128f6-6a25-40d4-aa28-12a4cc009e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-08 09:50:24.203438: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-08 09:50:24.669739: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cedabfc6-2e98-49bc-aeee-df087346bc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cdd8854-9311-4be3-9586-16b3a65c7293",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.saving.register_keras_serializable()\n",
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(units=128, activation=tf.nn.leaky_relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(units=1024, activation=tf.nn.leaky_relu)\n",
    "        self.dense3 = tf.keras.layers.Dense(units=128, activation=tf.nn.leaky_relu)\n",
    "        self.dense4 = tf.keras.layers.Dense(units=1024, activation=tf.nn.leaky_relu)\n",
    "        self.dense5 = tf.keras.layers.Dense(units=8)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dense4(x)\n",
    "        output = self.dense5(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "118567fd-5076-46e4-b005-11fd47d296db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParaServer:\n",
    "    def __init__(self):\n",
    "        self.model = MLP()\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        self.freqs = {}\n",
    "    def upload(self, grads, freq, score):\n",
    "        self.freqs[freq] = max(0, score)\n",
    "        self.optimizer.apply_gradients(grads_and_vars=zip(grads, self.model.variables))\n",
    "        return self.model, self.freqs\n",
    "    def download(self):\n",
    "        return self.model, self.freqs\n",
    "    def initModel(self, x):\n",
    "        self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9685fe4-7fee-4afd-82e6-6bbb2ac0b26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valiAll():\n",
    "    m, _ = ps.download()\n",
    "    model = copy.deepcopy(m)\n",
    "    y_v_p = model(X_v)\n",
    "    va_mse = tf.reduce_mean(tf.square(y_v_p - y_v))\n",
    "    va_rmse = tf.sqrt(va_mse)\n",
    "    va_mae = tf.reduce_mean(tf.abs(y_v_p - y_v))\n",
    "    va_r2 = 1 - tf.reduce_sum(tf.square(y_v_p - y_v)) / tf.reduce_sum(tf.square(y_v - tf.reduce_mean(y_v)))\n",
    "    print(\"mse:{} rmse:{} mae:{} r2:{}\".format(va_mse, va_rmse, va_mae, va_r2))\n",
    "    r2sv.append(va_r2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7262e7c8-f2ca-44ed-89ac-c1dc15a112c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, dsName, freq):\n",
    "        self.freq = freq\n",
    "        self.model = MLP()\n",
    "        dataset = pd.read_csv(dsName, encoding='utf-8')\n",
    "        self.X = dataset.loc[:,'freq':'L4'].to_numpy(dtype = np.float32)\n",
    "        self.y = dataset.loc[:,'S11r':'S41i'].to_numpy(dtype = np.float32)\n",
    "        self.dataset_train = tf.data.Dataset.from_tensor_slices((self.X, self.y))\n",
    "        self.dataset_train = self.dataset_train.shuffle(buffer_size=23000)\n",
    "        self.dataset_train = self.dataset_train.batch(batch_size)\n",
    "        self.dataset_train = self.dataset_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    def train(self, num_epochs):\n",
    "            m, freqs = ps.download()\n",
    "            freqs = copy.deepcopy(freqs)\n",
    "            zeroModel = copy.deepcopy(m)\n",
    "            for epoch_index in range(num_epochs):\n",
    "                for X, y in self.dataset_train:\n",
    "                    self.model = copy.deepcopy(m)\n",
    "                    X_self = X\n",
    "                    with tf.GradientTape() as tape:\n",
    "                        y_pred = self.model(X_self)\n",
    "                        tr_mse = tf.reduce_mean(tf.square(y_pred - y))\n",
    "                    tr_rmse = tf.sqrt(tr_mse)\n",
    "                    tr_mae = tf.reduce_mean(tf.abs(y_pred - y))\n",
    "                    tr_r2 = 1 - tf.reduce_sum(tf.square(y_pred - y)) / tf.reduce_sum(tf.square(y - tf.reduce_mean(y)))\n",
    "                    grads = tape.gradient(tr_mse, self.model.variables)\n",
    "                    sum_r2 = 1\n",
    "                    for k, v in freqs.items():\n",
    "                        if k == self.freq or v == 0:\n",
    "                            continue\n",
    "                        X_i = tf.tensor_scatter_nd_update(X, [[i, 0] for i in range(X.shape[0])], [k] * X.shape[0])\n",
    "                        y_i = zeroModel(X_i)\n",
    "                        with tf.GradientTape() as tape:\n",
    "                            y_pred_i = self.model(X_i)\n",
    "                            loss = tf.reduce_mean(tf.square(y_pred_i - y_i))\n",
    "                        grad = tape.gradient(loss, self.model.variables)\n",
    "                        grads = [grads[i] + grad[i] * v for i in range(len(grads))]\n",
    "                        sum_r2 += v\n",
    "                    m, _ = ps.upload([i / sum_r2 for i in grads], self.freq, tr_r2.numpy())\n",
    "                # if epoch_index in np.arange(0, num_epochs, 25).tolist() or epoch_index == num_epochs - 1:\n",
    "                if True:\n",
    "                    print(\"node:{} epoch:{}\".format(self.freq, epoch_index))\n",
    "                    print(\"train mse:{} rmse:{} mae:{} r2:{}\".format(tr_mse, tr_rmse, tr_mae, tr_r2))\n",
    "                    r2s.append(tr_r2.numpy())\n",
    "                    valiAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe7a98d7-a079-45e7-b987-ce12c5c461c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2s = []\n",
    "r2sv = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "616ac9e5-ba45-42bd-8003-9d69a78a6c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv(\"Test.csv\", encoding='utf-8')\n",
    "X_v = test_dataset.loc[:,'freq':'L4'].to_numpy(dtype = np.float32)\n",
    "y_v = test_dataset.loc[:,'S11r':'S41i'].to_numpy(dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a219205-21b5-48ee-b288-e0b0fafc616c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-08 09:50:35.370505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9604 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:17:00.0, compute capability: 7.5\n",
      "2023-09-08 09:50:35.371005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 9621 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "ps = ParaServer()\n",
    "ps.initModel(X_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5dbbbd6-52af-4fb3-9994-2b9b71f26078",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nodeList = [Node('./24Train.csv', 2.4), Node('./25Train.csv', 2.5), Node('./26Train.csv', 2.6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7941a46-9186-4a90-87a7-7a4b78d7f7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeList[0].train(150)\n",
    "nodeList[1].train(150)\n",
    "nodeList[2].train(150)\n",
    "nodeList[0].train(150)\n",
    "nodeList[1].train(150)\n",
    "nodeList[2].train(150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
