{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcb128f6-6a25-40d4-aa28-12a4cc009e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cedabfc6-2e98-49bc-aeee-df087346bc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cdd8854-9311-4be3-9586-16b3a65c7293",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.saving.register_keras_serializable()\n",
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(units=128, activation=tf.nn.leaky_relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(units=1024, activation=tf.nn.leaky_relu)\n",
    "        self.dense3 = tf.keras.layers.Dense(units=128, activation=tf.nn.leaky_relu)\n",
    "        self.dense4 = tf.keras.layers.Dense(units=1024, activation=tf.nn.leaky_relu)\n",
    "        self.dense5 = tf.keras.layers.Dense(units=8)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dense4(x)\n",
    "        output = self.dense5(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "118567fd-5076-46e4-b005-11fd47d296db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParaServer:\n",
    "    def __init__(self):\n",
    "        self.model = MLP()\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    def upload(self, grads):\n",
    "        self.optimizer.apply_gradients(grads_and_vars=zip(grads, self.model.variables))\n",
    "        return self.model\n",
    "    def download(self):\n",
    "        return self.model\n",
    "    def initModel(self, x):\n",
    "        self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9685fe4-7fee-4afd-82e6-6bbb2ac0b26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valiAll(index_epoch):\n",
    "    m = ps.download()\n",
    "    model = copy.deepcopy(m)\n",
    "    y_v_p = model(X_v)\n",
    "    va_mse = tf.reduce_mean(tf.square(y_v_p - y_v))\n",
    "    va_rmse = tf.sqrt(va_mse)\n",
    "    va_mae = tf.reduce_mean(tf.abs(y_v_p - y_v))\n",
    "    va_r2 = 1 - tf.reduce_sum(tf.square(y_v_p - y_v)) / tf.reduce_sum(tf.square(y_v - tf.reduce_mean(y_v)))\n",
    "    print(\"mse:{} rmse:{} mae:{} r2:{}\".format(va_mse, va_rmse, va_mae, va_r2))\n",
    "    r2sv[index_epoch] = va_r2.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7262e7c8-f2ca-44ed-89ac-c1dc15a112c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, freq):\n",
    "        self.freq = freq\n",
    "        self.model = MLP()\n",
    "        self.dataset = pd.read_csv('./trainset.csv', encoding='utf-8').sample(frac=1).reset_index(drop=True)\n",
    "        self.dataset = self.dataset[(self.dataset['freq'] >= freq[0]) & (self.dataset['freq'] <= freq[1])]\n",
    "        self.X = self.dataset.loc[:,'freq':'L2'].to_numpy(dtype = np.float32)\n",
    "        self.y = self.dataset.loc[:,'S11r':'S41i'].to_numpy(dtype = np.float32)\n",
    "        self.dataset_train = tf.data.Dataset.from_tensor_slices((self.X, self.y))\n",
    "        self.dataset_train = self.dataset_train.shuffle(buffer_size=23000)\n",
    "        self.dataset_train = self.dataset_train.batch(batch_size)\n",
    "        self.dataset_train = self.dataset_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    def train(self, index_epoch):\n",
    "        m = ps.download()\n",
    "        self.model = copy.deepcopy(m)\n",
    "        for X, y in self.dataset_train:\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = self.model(X)\n",
    "                tr_mse = tf.reduce_mean(tf.square(y_pred - y))\n",
    "            tr_rmse = tf.sqrt(tr_mse)\n",
    "            tr_mae = tf.reduce_mean(tf.abs(y_pred - y))\n",
    "            tr_r2 = 1 - tf.reduce_sum(tf.square(y_pred - y)) / tf.reduce_sum(tf.square(y - tf.reduce_mean(y)))\n",
    "            grads = tape.gradient(tr_mse, self.model.variables)\n",
    "            m = ps.upload(grads)\n",
    "            self.model = copy.deepcopy(m)\n",
    "        # if epoch_index in np.arange(0, num_epochs, 25).tolist() or epoch_index == num_epochs - 1:\n",
    "        if True:\n",
    "            print(\"node:{} epoch:{}\".format(self.freq, index_epoch))\n",
    "            print(\"train mse:{} rmse:{} mae:{} r2:{}\".format(tr_mse, tr_rmse, tr_mae, tr_r2))\n",
    "            r2s[self.freq[0]][index_epoch] = tr_r2.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe7a98d7-a079-45e7-b987-ce12c5c461c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2s = {1.0:{}, 2.7:{}, 4.4:{}}\n",
    "r2sv = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "616ac9e5-ba45-42bd-8003-9d69a78a6c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv(\"testset.csv\", encoding='utf-8').sample(frac=1).reset_index(drop=True)\n",
    "X_v = test_dataset.loc[:,'freq':'L2'].to_numpy(dtype = np.float32)\n",
    "y_v = test_dataset.loc[:,'S11r':'S41i'].to_numpy(dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a219205-21b5-48ee-b288-e0b0fafc616c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ps = ParaServer()\n",
    "ps.initModel(X_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5dbbbd6-52af-4fb3-9994-2b9b71f26078",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nodeList = [Node((1.0, 2.6)), Node((2.7, 4.3)), Node((4.4, 6.0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e83287a5-ca4c-42e8-a352-7e0774eea7e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 01:55:06.856912: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f64852b140 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-09-14 01:55:06.856932: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2023-09-14 01:55:06.856936: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2023-09-14 01:55:06.860048: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-09-14 01:55:06.951186: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-09-14 01:55:07.058633: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f7575f07040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f7575f07040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "node:(2.7, 4.3) epoch:0\n",
      "train mse:0.043809596449136734 rmse:0.20930741727352142 mae:0.16039542853832245 r2:0.6301136016845703\n",
      "mse:0.1492132693529129 rmse:0.3862813413143158 mae:0.3013881742954254 r2:-0.2220081090927124\n",
      "node:(2.7, 4.3) epoch:1\n",
      "train mse:0.03530925139784813 rmse:0.18790756165981293 mae:0.1421242356300354 r2:0.7042906284332275\n",
      "mse:0.16464200615882874 rmse:0.4057610034942627 mae:0.31490427255630493 r2:-0.3483644723892212\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m l, r \u001b[38;5;129;01min\u001b[39;00m turn[j]:\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m l \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m<\u001b[39m r:\n\u001b[0;32m----> 8\u001b[0m             \u001b[43mnodeList\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m valiAll(i)\n",
      "Cell \u001b[0;32mIn[12], line 24\u001b[0m, in \u001b[0;36mNode.train\u001b[0;34m(self, index_epoch)\u001b[0m\n\u001b[1;32m     22\u001b[0m     tr_r2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_sum(tf\u001b[38;5;241m.\u001b[39msquare(y_pred \u001b[38;5;241m-\u001b[39m y)) \u001b[38;5;241m/\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_sum(tf\u001b[38;5;241m.\u001b[39msquare(y \u001b[38;5;241m-\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(y)))\n\u001b[1;32m     23\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(tr_mse, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mvariables)\n\u001b[0;32m---> 24\u001b[0m     m \u001b[38;5;241m=\u001b[39m \u001b[43mps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# if epoch_index in np.arange(0, num_epochs, 25).tolist() or epoch_index == num_epochs - 1:\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m, in \u001b[0;36mParaServer.upload\u001b[0;34m(self, grads)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupload\u001b[39m(\u001b[38;5;28mself\u001b[39m, grads):\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n",
      "File \u001b[0;32m~/miniconda3/envs/jt_ma/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py:1230\u001b[0m, in \u001b[0;36mOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_gradients_aggregation \u001b[38;5;129;01mand\u001b[39;00m experimental_aggregate_gradients:\n\u001b[1;32m   1229\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate_gradients(grads_and_vars)\n\u001b[0;32m-> 1230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jt_ma/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py:652\u001b[0m, in \u001b[0;36m_BaseOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_weight_decay(trainable_variables)\n\u001b[1;32m    651\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, trainable_variables))\n\u001b[0;32m--> 652\u001b[0m iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_apply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;66;03m# Apply variable constraints after applying gradients.\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m trainable_variables:\n",
      "File \u001b[0;32m~/miniconda3/envs/jt_ma/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py:1260\u001b[0m, in \u001b[0;36mOptimizer._internal_apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mesh \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_with_dtensor:\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;66;03m# Skip any usage of strategy logic for DTensor\u001b[39;00m\n\u001b[1;32m   1258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_internal_apply_gradients(grads_and_vars)\n\u001b[0;32m-> 1260\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_merge_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distributed_apply_gradients_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1262\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distribution_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jt_ma/lib/python3.9/site-packages/tensorflow/python/distribute/merge_call_interim.py:51\u001b[0m, in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m  The return value of the `fn` call.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[0;32m---> 51\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m distribute_lib\u001b[38;5;241m.\u001b[39mget_replica_context()\u001b[38;5;241m.\u001b[39mmerge_call(\n\u001b[1;32m     54\u001b[0m       fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jt_ma/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py:1352\u001b[0m, in \u001b[0;36mOptimizer._distributed_apply_gradients_fn\u001b[0;34m(self, distribution, grads_and_vars, **kwargs)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_step(grad, var)\n\u001b[1;32m   1351\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m grad, var \u001b[38;5;129;01min\u001b[39;00m grads_and_vars:\n\u001b[0;32m-> 1352\u001b[0m     \u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_grad_to_update_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1354\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_ema:\n\u001b[1;32m   1357\u001b[0m     _, var_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mgrads_and_vars)\n",
      "File \u001b[0;32m~/miniconda3/envs/jt_ma/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2992\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2989\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   2990\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   2991\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 2992\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2993\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2994\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replica_ctx_update(\n\u001b[1;32m   2995\u001b[0m       var, fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs, group\u001b[38;5;241m=\u001b[39mgroup)\n",
      "File \u001b[0;32m~/miniconda3/envs/jt_ma/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:4062\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   4059\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[1;32m   4060\u001b[0m   \u001b[38;5;66;03m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[1;32m   4061\u001b[0m   \u001b[38;5;66;03m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[0;32m-> 4062\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_non_slot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jt_ma/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:4068\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   4064\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_non_slot\u001b[39m(\u001b[38;5;28mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[1;32m   4065\u001b[0m   \u001b[38;5;66;03m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[1;32m   4066\u001b[0m   \u001b[38;5;66;03m# once that value is used for something.\u001b[39;00m\n\u001b[1;32m   4067\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[0;32m-> 4068\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_group:\n\u001b[1;32m   4070\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/jt_ma/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:596\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    595\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mUNSPECIFIED):\n\u001b[0;32m--> 596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jt_ma/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py:1347\u001b[0m, in \u001b[0;36mOptimizer._distributed_apply_gradients_fn.<locals>.apply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_grad_to_update_var\u001b[39m(var, grad):\n\u001b[1;32m   1346\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit_compile:\n\u001b[0;32m-> 1347\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_step_xla\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_var_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1349\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_step(grad, var)\n",
      "File \u001b[0;32m~/miniconda3/envs/jt_ma/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/jt_ma/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/jt_ma/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:864\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    862\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 864\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/jt_ma/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jt_ma/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/jt_ma/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/envs/jt_ma/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/jt_ma/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "orders = [0, 1, 2]\n",
    "turn = [np.array([[26, 104], [178, 312], [344, 464], [520, 600]]), np.array([[0, 94], [149, 223], [319, 433], [464, 580]]), np.array([[32, 151], [155, 248], [270, 354], [378, 502]])]\n",
    "for i in range(600):\n",
    "    random.shuffle(orders)\n",
    "    for j in orders:\n",
    "        for l, r in turn[j]:\n",
    "            if l <= i < r:\n",
    "                nodeList[j].train(i)\n",
    "    valiAll(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76060fb9-5727-47b9-84d9-16bfb09b58e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5486207\n",
      "0.5958206\n",
      "0.6077136\n",
      "0.6231611\n",
      "0.6104752\n",
      "0.6293508\n",
      "0.6425981\n",
      "0.6651129\n",
      "0.6868254\n",
      "0.70473087\n",
      "0.7077899\n",
      "0.7163201\n",
      "0.74149126\n",
      "0.7564358\n",
      "0.7607001\n",
      "0.7586043\n",
      "0.7359556\n",
      "0.77295303\n",
      "0.7995131\n",
      "0.79581016\n",
      "0.81139106\n",
      "0.79567385\n",
      "0.7558851\n",
      "0.7826637\n",
      "0.7788899\n",
      "0.7793881\n",
      "0.8076835\n",
      "0.8089497\n",
      "0.8327596\n",
      "0.81962246\n",
      "0.7543961\n",
      "0.7840984\n",
      "0.81794167\n",
      "0.79270005\n",
      "0.82521594\n",
      "0.78134686\n",
      "0.83092093\n",
      "0.80101323\n",
      "0.8339965\n",
      "0.7948794\n",
      "0.84356713\n",
      "0.8465845\n",
      "0.79730135\n",
      "0.83424723\n",
      "0.8134524\n",
      "0.80595034\n",
      "0.83938706\n",
      "0.846708\n",
      "0.80759996\n",
      "0.84521496\n",
      "0.85964924\n",
      "0.81562316\n",
      "0.7884283\n",
      "0.8559452\n",
      "0.82728237\n",
      "0.8672112\n",
      "0.859355\n",
      "0.8188611\n",
      "0.8648717\n",
      "0.86271995\n",
      "0.79972637\n",
      "0.85287476\n",
      "0.8543722\n",
      "0.8266123\n",
      "0.82080746\n",
      "0.8168412\n",
      "0.8181273\n",
      "0.8719065\n",
      "0.82265854\n",
      "0.8701856\n",
      "0.8311549\n",
      "0.8286662\n",
      "0.8626292\n",
      "0.87516916\n",
      "0.8826012\n",
      "0.8897865\n",
      "0.8933047\n",
      "0.89149964\n",
      "0.89433753\n",
      "0.89729017\n",
      "0.8999928\n",
      "0.8984779\n",
      "0.9020348\n",
      "0.88937795\n",
      "0.90497017\n",
      "0.8998585\n",
      "0.89999324\n",
      "0.9050486\n",
      "0.90359885\n",
      "0.9058355\n",
      "0.91599554\n",
      "0.9061472\n",
      "0.9080994\n",
      "0.90987\n",
      "0.9071824\n",
      "0.9126997\n",
      "0.9149367\n",
      "0.9061122\n",
      "0.9152161\n",
      "0.915922\n",
      "0.9087743\n",
      "0.91429985\n",
      "0.91539156\n",
      "0.91490686\n",
      "0.9165493\n",
      "0.9112474\n",
      "0.91372794\n",
      "0.91544247\n",
      "0.9142804\n",
      "0.9137143\n",
      "0.9175518\n",
      "0.9155392\n",
      "0.923803\n",
      "0.92633957\n",
      "0.91276205\n",
      "0.9209438\n",
      "0.918486\n",
      "0.9029117\n",
      "0.92548037\n",
      "0.88179857\n",
      "0.92150605\n",
      "0.90989375\n",
      "0.899019\n",
      "0.89616954\n",
      "0.9025525\n",
      "0.91745234\n",
      "0.90679806\n",
      "0.90057766\n",
      "0.90614915\n",
      "0.92569166\n",
      "0.9038785\n",
      "0.90373534\n",
      "0.90629023\n",
      "0.90546477\n",
      "0.9057583\n",
      "0.8987281\n",
      "0.9282632\n",
      "0.9073674\n",
      "0.91042876\n",
      "0.913741\n",
      "0.9301899\n",
      "0.9128838\n",
      "0.9290821\n",
      "0.9140121\n",
      "0.9002106\n",
      "0.92927235\n",
      "0.8607079\n",
      "0.8641455\n",
      "0.9060787\n",
      "0.8614872\n",
      "0.9008947\n",
      "0.8501718\n",
      "0.9086918\n",
      "0.910839\n",
      "0.92558277\n",
      "0.8514681\n",
      "0.84425396\n",
      "0.9157859\n",
      "0.85321957\n",
      "0.85675603\n",
      "0.859818\n",
      "0.861181\n",
      "0.9106826\n",
      "0.8597066\n",
      "0.90321845\n",
      "0.9246956\n",
      "0.8639226\n",
      "0.91353893\n",
      "0.8573888\n",
      "0.901754\n",
      "0.9214706\n",
      "0.8988825\n",
      "0.86392075\n",
      "0.8685833\n",
      "0.9134662\n",
      "0.8709637\n",
      "0.84628\n",
      "0.87008\n",
      "0.8710019\n",
      "0.9012074\n",
      "0.87487787\n",
      "0.8592549\n",
      "0.9009172\n",
      "0.9101723\n",
      "0.84724194\n",
      "0.90282947\n",
      "0.9050001\n",
      "0.87183356\n",
      "0.85058737\n",
      "0.907964\n",
      "0.8609389\n",
      "0.91027075\n",
      "0.86235785\n",
      "0.84615153\n",
      "0.8544132\n",
      "0.91369104\n",
      "0.8690246\n",
      "0.84743124\n",
      "0.8510712\n",
      "0.851512\n",
      "0.8553705\n",
      "0.8628721\n",
      "0.89992315\n",
      "0.8558389\n",
      "0.8502142\n",
      "0.91339236\n",
      "0.85890156\n",
      "0.8500684\n",
      "0.9126121\n",
      "0.8640598\n",
      "0.8599427\n",
      "0.9117364\n",
      "0.7109257\n",
      "0.8193221\n",
      "0.8337545\n",
      "0.88605547\n",
      "0.81883204\n",
      "0.85358465\n",
      "0.83089364\n",
      "0.90062904\n",
      "0.8474817\n",
      "0.84207284\n",
      "0.8588952\n",
      "0.8570152\n",
      "0.85794103\n",
      "0.8523793\n",
      "0.85647017\n",
      "0.8634623\n",
      "0.8569515\n",
      "0.9046787\n",
      "0.8604654\n",
      "0.86385596\n",
      "0.8536985\n",
      "0.85832936\n",
      "0.85821164\n",
      "0.86393636\n",
      "0.86024106\n",
      "0.85721684\n",
      "0.8645629\n",
      "0.8591993\n",
      "0.9068277\n",
      "0.86010313\n",
      "0.9047585\n",
      "0.8594001\n",
      "0.86142933\n",
      "0.85636485\n",
      "0.91441846\n",
      "0.86152476\n",
      "0.8638941\n",
      "0.9106494\n",
      "0.8677802\n",
      "0.86846983\n",
      "0.917637\n",
      "0.8617935\n",
      "0.860693\n",
      "0.9096911\n",
      "0.9210368\n",
      "0.9277075\n",
      "0.9335046\n",
      "0.9360417\n",
      "0.93587303\n",
      "0.9228362\n",
      "0.9358302\n",
      "0.91767687\n",
      "0.9274474\n",
      "0.92698425\n",
      "0.93675894\n",
      "0.9282618\n",
      "0.9363724\n",
      "0.93401295\n",
      "0.94212425\n",
      "0.91889673\n",
      "0.9454642\n",
      "0.92650867\n",
      "0.94916695\n",
      "0.9263209\n",
      "0.9444244\n",
      "0.93509233\n",
      "0.9353124\n",
      "0.93203974\n",
      "0.9384002\n",
      "0.9410622\n",
      "0.94685555\n",
      "0.9367459\n",
      "0.9401053\n",
      "0.95218796\n",
      "0.89614844\n",
      "0.89496297\n",
      "0.9414814\n",
      "0.923407\n",
      "0.90001684\n",
      "0.9316412\n",
      "0.89334327\n",
      "0.8836427\n",
      "0.9209096\n",
      "0.9257424\n",
      "0.8917959\n",
      "0.9246576\n",
      "0.92889696\n",
      "0.8958209\n",
      "0.8822546\n",
      "0.9284071\n",
      "0.9258106\n",
      "0.8850021\n",
      "0.883881\n",
      "0.8791962\n",
      "0.92301834\n",
      "0.88294435\n",
      "0.892194\n",
      "0.9250844\n",
      "0.92842263\n",
      "0.8878936\n",
      "0.88818806\n",
      "0.92039454\n",
      "0.929348\n",
      "0.93171144\n",
      "0.8915452\n",
      "0.8837719\n",
      "0.91998047\n",
      "0.88178366\n",
      "0.9240483\n",
      "0.8960675\n",
      "0.92625886\n",
      "0.9401985\n",
      "0.8887551\n",
      "0.9282234\n",
      "0.92367536\n",
      "0.8956187\n",
      "0.92483795\n",
      "0.8828955\n",
      "0.93422335\n",
      "0.927166\n",
      "0.9256541\n",
      "0.94507295\n",
      "0.8891503\n",
      "0.9319037\n",
      "0.9333059\n",
      "0.8904024\n",
      "0.9299299\n",
      "0.92570555\n",
      "0.88680613\n",
      "0.932909\n",
      "0.9293877\n",
      "0.94693094\n",
      "0.9303199\n",
      "0.92896557\n",
      "0.93446463\n",
      "0.93472826\n",
      "0.9472699\n",
      "0.93481123\n",
      "0.9533663\n",
      "0.89982504\n",
      "0.9397973\n",
      "0.8991986\n",
      "0.90491456\n",
      "0.8843293\n",
      "0.8838628\n",
      "0.8929259\n",
      "0.88447267\n",
      "0.9304621\n",
      "0.8985095\n",
      "0.92976344\n",
      "0.8973378\n",
      "0.8926461\n",
      "0.8887696\n",
      "0.8852718\n",
      "0.8919926\n",
      "0.88846916\n",
      "0.9341674\n",
      "0.8978403\n",
      "0.8938506\n",
      "0.8907316\n",
      "0.89091206\n",
      "0.8936493\n",
      "0.9279437\n",
      "0.8967063\n",
      "0.8919613\n",
      "0.9338268\n",
      "0.89639634\n",
      "0.8860094\n",
      "0.9301632\n",
      "0.8955811\n",
      "0.9160827\n",
      "0.9265883\n",
      "0.9422995\n",
      "0.92716396\n",
      "0.93743527\n",
      "0.9500137\n",
      "0.94115126\n",
      "0.934649\n",
      "0.956965\n",
      "0.93780786\n",
      "0.9361402\n",
      "0.9443657\n",
      "0.9546206\n",
      "0.9378155\n",
      "0.95274293\n",
      "0.9366823\n",
      "0.95810986\n",
      "0.94690424\n",
      "0.94390035\n",
      "0.9550173\n",
      "0.9422322\n",
      "0.9574665\n",
      "0.93710375\n",
      "0.94203156\n",
      "0.9436994\n",
      "0.959785\n",
      "0.94684917\n",
      "0.941917\n",
      "0.9572559\n",
      "0.9463945\n",
      "0.9593562\n",
      "0.9471763\n",
      "0.9442424\n",
      "0.94346356\n",
      "0.94581413\n",
      "0.96329355\n",
      "0.9441694\n",
      "0.96196514\n"
     ]
    }
   ],
   "source": [
    "for k, v in r2s[2.6].items():\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b60e74c-3be0-48a1-b6f2-d5ddd041d9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421d7963-a6fd-4ce2-98aa-ee920b37eef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
