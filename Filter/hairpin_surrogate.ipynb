{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d8adcbb-cfb7-4a33-8f35-ed8142ad1b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 12:32:08.297933: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-01 12:32:08.766538: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ac05223-c90a-4459-9038-f553d3e689dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "tf.config.experimental.set_visible_devices(gpus[1], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef40b689-1bfe-4685-abd7-731b0c54e86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "EPOCHS = 300\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "decay_steps = 1000  # 每隔多少个steps衰减一次\n",
    "decay_rate = 0.96  # 学习率衰减因子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fed2607-102f-49b5-b06f-d4cd17b9a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset = pd.read_csv('./hairpin_filter_dataset.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acca4368-afcf-4d40-85ee-0c8c7a06efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_AS_dataset = AS_dataset[(AS_dataset['freq'] >= 2.5) & (AS_dataset['freq'] <= 6.5)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1d68c42-e280-4c77-821f-f1fc396f57b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X = selected_AS_dataset.loc[:,'freq':'S1'].to_numpy(dtype = np.float32)\n",
    "full_y = selected_AS_dataset.loc[:,'S21r':'S21i'].to_numpy(dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "074e7f35-2b53-4f73-a7bb-fb57804de332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化\n",
    "# full_X[0] = (full_X[0] - 0.1) / (9.0 - 0.1)\n",
    "full_X[:, 1] = (full_X[:, 1] - 200) / (2000 - 200)\n",
    "full_X[:, 2] = (full_X[:, 2] - 200) / (2000 - 200)\n",
    "full_X[:, 3] = (full_X[:, 3] - 200) / (2000 - 200)\n",
    "full_X[:, 4] = (full_X[:, 4] - 200) / (4500 - 200)\n",
    "full_X[:, 5] = (full_X[:, 5] - 200) / (4500 - 200)\n",
    "full_X[:, 6] = (full_X[:, 6] - 200) / (4500 - 200)\n",
    "full_X[:, 7] = (full_X[:, 7] - 200) / (4500 - 200)\n",
    "full_X[:, 8] = (full_X[:, 8] - 9000) / (12000 - 9000)\n",
    "full_X[:, 9] = (full_X[:, 9] - 100) / (300 - 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcb43ce1-5dac-481a-a89c-b62f13d92af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_vali, y_train, y_vali = train_test_split(full_X, full_y, test_size=0.05, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caf60e95-67f7-43a9-851f-b051b02eb4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 12:32:10.642079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9285 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "dataset_train = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "dataset_train = dataset_train.shuffle(buffer_size=X_train.shape[0])\n",
    "dataset_train = dataset_train.batch(BATCH_SIZE)\n",
    "dataset_train = dataset_train.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58ab559c-1e0a-4e2d-8b34-743ad829d6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_vali = tf.data.Dataset.from_tensor_slices((X_vali, y_vali))\n",
    "dataset_vali = dataset_vali.shuffle(buffer_size=X_vali.shape[0])\n",
    "dataset_vali = dataset_vali.batch(BATCH_SIZE)\n",
    "dataset_vali = dataset_vali.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe17ca0b-224c-43ac-a21c-d10a6fd0f17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class R2Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='r2_score', **kwargs):\n",
    "        super(R2Score, self).__init__(name=name, **kwargs)\n",
    "        self.squared_errors = self.add_weight(name='squared_errors', initializer='zeros')\n",
    "        self.total_squared_errors = self.add_weight(name='total_squared_errors', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        if sample_weight is not None:\n",
    "            y_true = tf.multiply(y_true, tf.cast(sample_weight, tf.float32))\n",
    "            y_pred = tf.multiply(y_pred, tf.cast(sample_weight, tf.float32))\n",
    "\n",
    "        SS_res = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        SS_tot = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)))\n",
    "\n",
    "        self.squared_errors.assign(SS_res)\n",
    "        self.total_squared_errors.assign(SS_tot)\n",
    "\n",
    "    def result(self):\n",
    "        return 1 - self.squared_errors / (self.total_squared_errors + tf.keras.backend.epsilon())\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.squared_errors.assign(0.)\n",
    "        self.total_squared_errors.assign(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "441fa2e0-6b4b-4ed6-804e-dc7940e9c7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(modelDict):\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    for d in modelDict:\n",
    "        model.add(tf.keras.layers.Dense(units=d['units'], activation=d['activation']))\n",
    "        if d['withNorm']:\n",
    "            model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dense(2))\n",
    "    \n",
    "    learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate,\n",
    "        decay_steps,\n",
    "        decay_rate,\n",
    "        staircase=True  # 是否以指数方式精确衰减，默认False，若为True则每隔decay_steps学习率按decay_rate衰减\n",
    "    )\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "              loss='mean_squared_error',\n",
    "              metrics=[R2Score()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60091909-400d-44c2-a28c-9813a3a9c693",
   "metadata": {},
   "outputs": [],
   "source": [
    "NA1 = [{'units': 512, 'activation': 'leaky_relu', 'withNorm': True}, \n",
    "       {'units': 512, 'activation': 'leaky_relu', 'withNorm': False}, \n",
    "       {'units': 128, 'activation': 'leaky_relu', 'withNorm': False},\n",
    "       {'units': 160, 'activation': 'leaky_relu', 'withNorm': False}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b66de96-d3dd-4f75-a11c-c7b9f9ce2d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with mirrored_strategy.scope():\n",
    "model = build_model(NA1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee3dfe5b-dac0-42ac-8c81-ccbb817f86b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('bestsofar.h5', monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                             mode='min',\n",
    "                             save_weights_only=True)\n",
    "\n",
    "# tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b43ab47-7a98-41a7-a4a0-660f7c60aea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c93ffd99-8050-4516-b3ee-c5758eaf42f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 12:32:12.370324: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561a78f23bc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-01 12:32:12.370374: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2024-05-01 12:32:12.381190: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-01 12:32:12.495021: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2024-05-01 12:32:12.601299: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756/761 [============================>.] - ETA: 0s - loss: 0.0733 - r2_score: 0.6967\n",
      "Epoch 1: val_loss improved from inf to 0.04330, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 6s 4ms/step - loss: 0.0731 - r2_score: 0.6267 - val_loss: 0.0433 - val_r2_score: 0.5375\n",
      "Epoch 2/300\n",
      "758/761 [============================>.] - ETA: 0s - loss: 0.0412 - r2_score: 0.7314\n",
      "Epoch 2: val_loss improved from 0.04330 to 0.04179, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0413 - r2_score: -0.0620 - val_loss: 0.0418 - val_r2_score: 0.6509\n",
      "Epoch 3/300\n",
      "751/761 [============================>.] - ETA: 0s - loss: 0.0344 - r2_score: 0.4212\n",
      "Epoch 3: val_loss improved from 0.04179 to 0.02353, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0344 - r2_score: 0.2984 - val_loss: 0.0235 - val_r2_score: 0.7575\n",
      "Epoch 4/300\n",
      "749/761 [============================>.] - ETA: 0s - loss: 0.0348 - r2_score: 0.7257\n",
      "Epoch 4: val_loss improved from 0.02353 to 0.01987, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0347 - r2_score: 0.8510 - val_loss: 0.0199 - val_r2_score: 0.8729\n",
      "Epoch 5/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0319 - r2_score: 0.8435\n",
      "Epoch 5: val_loss improved from 0.01987 to 0.01505, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0319 - r2_score: 0.7004 - val_loss: 0.0151 - val_r2_score: 0.7273\n",
      "Epoch 6/300\n",
      "751/761 [============================>.] - ETA: 0s - loss: 0.0317 - r2_score: 0.8009\n",
      "Epoch 6: val_loss improved from 0.01505 to 0.01450, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0316 - r2_score: 0.8616 - val_loss: 0.0145 - val_r2_score: 0.8814\n",
      "Epoch 7/300\n",
      "757/761 [============================>.] - ETA: 0s - loss: 0.0299 - r2_score: 0.8143\n",
      "Epoch 7: val_loss did not improve from 0.01450\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0299 - r2_score: 0.7397 - val_loss: 0.0193 - val_r2_score: 0.7864\n",
      "Epoch 8/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0304 - r2_score: 0.8047\n",
      "Epoch 8: val_loss did not improve from 0.01450\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0304 - r2_score: 0.8401 - val_loss: 0.0170 - val_r2_score: 0.8926\n",
      "Epoch 9/300\n",
      "757/761 [============================>.] - ETA: 0s - loss: 0.0284 - r2_score: 0.7128\n",
      "Epoch 9: val_loss did not improve from 0.01450\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0285 - r2_score: 0.8712 - val_loss: 0.0200 - val_r2_score: 0.8218\n",
      "Epoch 10/300\n",
      "760/761 [============================>.] - ETA: 0s - loss: 0.0276 - r2_score: 0.3945\n",
      "Epoch 10: val_loss improved from 0.01450 to 0.01186, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0276 - r2_score: 0.8172 - val_loss: 0.0119 - val_r2_score: 0.8535\n",
      "Epoch 11/300\n",
      "748/761 [============================>.] - ETA: 0s - loss: 0.0279 - r2_score: 0.8839\n",
      "Epoch 11: val_loss did not improve from 0.01186\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0281 - r2_score: 0.1725 - val_loss: 0.0184 - val_r2_score: 0.8285\n",
      "Epoch 12/300\n",
      "750/761 [============================>.] - ETA: 0s - loss: 0.0251 - r2_score: 0.0187\n",
      "Epoch 12: val_loss did not improve from 0.01186\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0253 - r2_score: 0.5876 - val_loss: 0.0364 - val_r2_score: 0.6666\n",
      "Epoch 13/300\n",
      "756/761 [============================>.] - ETA: 0s - loss: 0.0267 - r2_score: 0.5710\n",
      "Epoch 13: val_loss did not improve from 0.01186\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0268 - r2_score: 0.6372 - val_loss: 0.0156 - val_r2_score: 0.8763\n",
      "Epoch 14/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0252 - r2_score: 0.8300\n",
      "Epoch 14: val_loss did not improve from 0.01186\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0253 - r2_score: 0.6348 - val_loss: 0.0136 - val_r2_score: 0.8480\n",
      "Epoch 15/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0260 - r2_score: 0.7602\n",
      "Epoch 15: val_loss did not improve from 0.01186\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0261 - r2_score: 0.7309 - val_loss: 0.0231 - val_r2_score: 0.7975\n",
      "Epoch 16/300\n",
      "757/761 [============================>.] - ETA: 0s - loss: 0.0249 - r2_score: 0.5465\n",
      "Epoch 16: val_loss did not improve from 0.01186\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0249 - r2_score: 0.7385 - val_loss: 0.0198 - val_r2_score: 0.8246\n",
      "Epoch 17/300\n",
      "754/761 [============================>.] - ETA: 0s - loss: 0.0253 - r2_score: 0.9100\n",
      "Epoch 17: val_loss did not improve from 0.01186\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0253 - r2_score: 0.9009 - val_loss: 0.0239 - val_r2_score: 0.7515\n",
      "Epoch 18/300\n",
      "760/761 [============================>.] - ETA: 0s - loss: 0.0232 - r2_score: 0.7446\n",
      "Epoch 18: val_loss did not improve from 0.01186\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0231 - r2_score: 0.9252 - val_loss: 0.0305 - val_r2_score: 0.4929\n",
      "Epoch 19/300\n",
      "754/761 [============================>.] - ETA: 0s - loss: 0.0229 - r2_score: 0.5210\n",
      "Epoch 19: val_loss did not improve from 0.01186\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0228 - r2_score: 0.7618 - val_loss: 0.0158 - val_r2_score: 0.8364\n",
      "Epoch 20/300\n",
      "761/761 [==============================] - ETA: 0s - loss: 0.0252 - r2_score: 0.5553\n",
      "Epoch 20: val_loss improved from 0.01186 to 0.00919, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0252 - r2_score: 0.5553 - val_loss: 0.0092 - val_r2_score: 0.9299\n",
      "Epoch 21/300\n",
      "750/761 [============================>.] - ETA: 0s - loss: 0.0237 - r2_score: 0.8755\n",
      "Epoch 21: val_loss did not improve from 0.00919\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0236 - r2_score: 0.7984 - val_loss: 0.0148 - val_r2_score: 0.9182\n",
      "Epoch 22/300\n",
      "758/761 [============================>.] - ETA: 0s - loss: 0.0226 - r2_score: 0.7586\n",
      "Epoch 22: val_loss did not improve from 0.00919\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0226 - r2_score: 0.9037 - val_loss: 0.0358 - val_r2_score: 0.6113\n",
      "Epoch 23/300\n",
      "751/761 [============================>.] - ETA: 0s - loss: 0.0226 - r2_score: 0.7881\n",
      "Epoch 23: val_loss did not improve from 0.00919\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0227 - r2_score: 0.8613 - val_loss: 0.0313 - val_r2_score: 0.7852\n",
      "Epoch 24/300\n",
      "761/761 [==============================] - ETA: 0s - loss: 0.0224 - r2_score: 0.4807\n",
      "Epoch 24: val_loss did not improve from 0.00919\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0224 - r2_score: 0.4807 - val_loss: 0.0501 - val_r2_score: 0.3630\n",
      "Epoch 25/300\n",
      "761/761 [==============================] - ETA: 0s - loss: 0.0208 - r2_score: 0.7233\n",
      "Epoch 25: val_loss did not improve from 0.00919\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0208 - r2_score: 0.7233 - val_loss: 0.0100 - val_r2_score: 0.9214\n",
      "Epoch 26/300\n",
      "755/761 [============================>.] - ETA: 0s - loss: 0.0216 - r2_score: 0.5700\n",
      "Epoch 26: val_loss did not improve from 0.00919\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0215 - r2_score: 0.9345 - val_loss: 0.0094 - val_r2_score: 0.9106\n",
      "Epoch 27/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0198 - r2_score: 0.8942\n",
      "Epoch 27: val_loss did not improve from 0.00919\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0198 - r2_score: 0.8199 - val_loss: 0.0325 - val_r2_score: 0.7133\n",
      "Epoch 28/300\n",
      "756/761 [============================>.] - ETA: 0s - loss: 0.0196 - r2_score: 0.8921\n",
      "Epoch 28: val_loss did not improve from 0.00919\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0196 - r2_score: 0.9244 - val_loss: 0.0136 - val_r2_score: 0.7814\n",
      "Epoch 29/300\n",
      "750/761 [============================>.] - ETA: 0s - loss: 0.0211 - r2_score: 0.7550\n",
      "Epoch 29: val_loss improved from 0.00919 to 0.00634, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0210 - r2_score: 0.8166 - val_loss: 0.0063 - val_r2_score: 0.9692\n",
      "Epoch 30/300\n",
      "751/761 [============================>.] - ETA: 0s - loss: 0.0201 - r2_score: 0.7677\n",
      "Epoch 30: val_loss did not improve from 0.00634\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0200 - r2_score: 0.8581 - val_loss: 0.0131 - val_r2_score: 0.9355\n",
      "Epoch 31/300\n",
      "754/761 [============================>.] - ETA: 0s - loss: 0.0180 - r2_score: 0.9134\n",
      "Epoch 31: val_loss did not improve from 0.00634\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0180 - r2_score: 0.7495 - val_loss: 0.0151 - val_r2_score: 0.9113\n",
      "Epoch 32/300\n",
      "758/761 [============================>.] - ETA: 0s - loss: 0.0181 - r2_score: 0.7453\n",
      "Epoch 32: val_loss did not improve from 0.00634\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0181 - r2_score: 0.8404 - val_loss: 0.0253 - val_r2_score: 0.5792\n",
      "Epoch 33/300\n",
      "759/761 [============================>.] - ETA: 0s - loss: 0.0171 - r2_score: 0.9019\n",
      "Epoch 33: val_loss did not improve from 0.00634\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0171 - r2_score: 0.8425 - val_loss: 0.0231 - val_r2_score: 0.7530\n",
      "Epoch 34/300\n",
      "758/761 [============================>.] - ETA: 0s - loss: 0.0166 - r2_score: 0.8862\n",
      "Epoch 34: val_loss improved from 0.00634 to 0.00612, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0165 - r2_score: 0.8130 - val_loss: 0.0061 - val_r2_score: 0.9604\n",
      "Epoch 35/300\n",
      "754/761 [============================>.] - ETA: 0s - loss: 0.0159 - r2_score: 0.9218\n",
      "Epoch 35: val_loss did not improve from 0.00612\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0159 - r2_score: 0.9150 - val_loss: 0.0162 - val_r2_score: 0.8187\n",
      "Epoch 36/300\n",
      "751/761 [============================>.] - ETA: 0s - loss: 0.0158 - r2_score: 0.5249\n",
      "Epoch 36: val_loss did not improve from 0.00612\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0159 - r2_score: 0.9347 - val_loss: 0.0298 - val_r2_score: 0.6079\n",
      "Epoch 37/300\n",
      "754/761 [============================>.] - ETA: 0s - loss: 0.0135 - r2_score: 0.8382\n",
      "Epoch 37: val_loss did not improve from 0.00612\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0136 - r2_score: 0.5950 - val_loss: 0.0234 - val_r2_score: 0.7582\n",
      "Epoch 38/300\n",
      "761/761 [==============================] - ETA: 0s - loss: 0.0127 - r2_score: 0.6784\n",
      "Epoch 38: val_loss did not improve from 0.00612\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0127 - r2_score: 0.6784 - val_loss: 0.0114 - val_r2_score: 0.7782\n",
      "Epoch 39/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0131 - r2_score: 0.8364\n",
      "Epoch 39: val_loss did not improve from 0.00612\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0131 - r2_score: 0.8778 - val_loss: 0.0254 - val_r2_score: 0.6605\n",
      "Epoch 40/300\n",
      "759/761 [============================>.] - ETA: 0s - loss: 0.0117 - r2_score: 0.6593\n",
      "Epoch 40: val_loss did not improve from 0.00612\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0117 - r2_score: 0.8895 - val_loss: 0.0077 - val_r2_score: 0.9598\n",
      "Epoch 41/300\n",
      "755/761 [============================>.] - ETA: 0s - loss: 0.0116 - r2_score: 0.9294\n",
      "Epoch 41: val_loss did not improve from 0.00612\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0116 - r2_score: 0.9025 - val_loss: 0.0115 - val_r2_score: 0.9280\n",
      "Epoch 42/300\n",
      "760/761 [============================>.] - ETA: 0s - loss: 0.0112 - r2_score: 0.9128\n",
      "Epoch 42: val_loss did not improve from 0.00612\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0112 - r2_score: 0.9407 - val_loss: 0.0065 - val_r2_score: 0.9105\n",
      "Epoch 43/300\n",
      "755/761 [============================>.] - ETA: 0s - loss: 0.0102 - r2_score: 0.9332\n",
      "Epoch 43: val_loss did not improve from 0.00612\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0102 - r2_score: 0.9066 - val_loss: 0.0077 - val_r2_score: 0.9288\n",
      "Epoch 44/300\n",
      "758/761 [============================>.] - ETA: 0s - loss: 0.0099 - r2_score: 0.8509\n",
      "Epoch 44: val_loss improved from 0.00612 to 0.00458, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0099 - r2_score: 0.8991 - val_loss: 0.0046 - val_r2_score: 0.9394\n",
      "Epoch 45/300\n",
      "759/761 [============================>.] - ETA: 0s - loss: 0.0100 - r2_score: 0.9568\n",
      "Epoch 45: val_loss did not improve from 0.00458\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0100 - r2_score: 0.9175 - val_loss: 0.0091 - val_r2_score: 0.8468\n",
      "Epoch 46/300\n",
      "760/761 [============================>.] - ETA: 0s - loss: 0.0096 - r2_score: 0.8919\n",
      "Epoch 46: val_loss did not improve from 0.00458\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0096 - r2_score: 0.9363 - val_loss: 0.0052 - val_r2_score: 0.8596\n",
      "Epoch 47/300\n",
      "756/761 [============================>.] - ETA: 0s - loss: 0.0095 - r2_score: 0.9466\n",
      "Epoch 47: val_loss did not improve from 0.00458\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0095 - r2_score: 0.9413 - val_loss: 0.0048 - val_r2_score: 0.9820\n",
      "Epoch 48/300\n",
      "759/761 [============================>.] - ETA: 0s - loss: 0.0091 - r2_score: 0.9530\n",
      "Epoch 48: val_loss improved from 0.00458 to 0.00376, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0091 - r2_score: 0.9141 - val_loss: 0.0038 - val_r2_score: 0.9607\n",
      "Epoch 49/300\n",
      "759/761 [============================>.] - ETA: 0s - loss: 0.0089 - r2_score: 0.8773\n",
      "Epoch 49: val_loss did not improve from 0.00376\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0089 - r2_score: 0.8670 - val_loss: 0.0069 - val_r2_score: 0.9416\n",
      "Epoch 50/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0083 - r2_score: 0.9275\n",
      "Epoch 50: val_loss did not improve from 0.00376\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0083 - r2_score: 0.9558 - val_loss: 0.0064 - val_r2_score: 0.9416\n",
      "Epoch 51/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0085 - r2_score: 0.7192\n",
      "Epoch 51: val_loss did not improve from 0.00376\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0085 - r2_score: 0.9374 - val_loss: 0.0085 - val_r2_score: 0.9510\n",
      "Epoch 52/300\n",
      "757/761 [============================>.] - ETA: 0s - loss: 0.0079 - r2_score: 0.9561\n",
      "Epoch 52: val_loss did not improve from 0.00376\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0079 - r2_score: 0.7897 - val_loss: 0.0042 - val_r2_score: 0.8856\n",
      "Epoch 53/300\n",
      "755/761 [============================>.] - ETA: 0s - loss: 0.0076 - r2_score: 0.9452\n",
      "Epoch 53: val_loss did not improve from 0.00376\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0075 - r2_score: 0.9461 - val_loss: 0.0052 - val_r2_score: 0.9448\n",
      "Epoch 54/300\n",
      "760/761 [============================>.] - ETA: 0s - loss: 0.0082 - r2_score: 0.9297\n",
      "Epoch 54: val_loss did not improve from 0.00376\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0082 - r2_score: 0.9390 - val_loss: 0.0069 - val_r2_score: 0.8819\n",
      "Epoch 55/300\n",
      "758/761 [============================>.] - ETA: 0s - loss: 0.0076 - r2_score: 0.9495\n",
      "Epoch 55: val_loss did not improve from 0.00376\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0076 - r2_score: 0.9486 - val_loss: 0.0046 - val_r2_score: 0.9709\n",
      "Epoch 56/300\n",
      "755/761 [============================>.] - ETA: 0s - loss: 0.0075 - r2_score: 0.9477\n",
      "Epoch 56: val_loss did not improve from 0.00376\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0075 - r2_score: 0.9221 - val_loss: 0.0069 - val_r2_score: 0.9726\n",
      "Epoch 57/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0074 - r2_score: 0.9294\n",
      "Epoch 57: val_loss improved from 0.00376 to 0.00252, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0074 - r2_score: 0.9206 - val_loss: 0.0025 - val_r2_score: 0.9921\n",
      "Epoch 58/300\n",
      "755/761 [============================>.] - ETA: 0s - loss: 0.0073 - r2_score: 0.8595\n",
      "Epoch 58: val_loss did not improve from 0.00252\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0073 - r2_score: 0.7188 - val_loss: 0.0142 - val_r2_score: 0.7576\n",
      "Epoch 59/300\n",
      "759/761 [============================>.] - ETA: 0s - loss: 0.0070 - r2_score: 0.9422\n",
      "Epoch 59: val_loss did not improve from 0.00252\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0070 - r2_score: 0.8695 - val_loss: 0.0077 - val_r2_score: 0.8672\n",
      "Epoch 60/300\n",
      "755/761 [============================>.] - ETA: 0s - loss: 0.0069 - r2_score: 0.9215\n",
      "Epoch 60: val_loss did not improve from 0.00252\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0068 - r2_score: 0.9582 - val_loss: 0.0074 - val_r2_score: 0.9327\n",
      "Epoch 61/300\n",
      "750/761 [============================>.] - ETA: 0s - loss: 0.0065 - r2_score: 0.9295\n",
      "Epoch 61: val_loss did not improve from 0.00252\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0066 - r2_score: 0.9422 - val_loss: 0.0036 - val_r2_score: 0.9694\n",
      "Epoch 62/300\n",
      "751/761 [============================>.] - ETA: 0s - loss: 0.0068 - r2_score: 0.9332\n",
      "Epoch 62: val_loss did not improve from 0.00252\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0068 - r2_score: 0.9125 - val_loss: 0.0122 - val_r2_score: 0.8663\n",
      "Epoch 63/300\n",
      "749/761 [============================>.] - ETA: 0s - loss: 0.0065 - r2_score: 0.9635\n",
      "Epoch 63: val_loss did not improve from 0.00252\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0065 - r2_score: 0.9286 - val_loss: 0.0067 - val_r2_score: 0.9328\n",
      "Epoch 64/300\n",
      "756/761 [============================>.] - ETA: 0s - loss: 0.0063 - r2_score: 0.9405\n",
      "Epoch 64: val_loss did not improve from 0.00252\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0063 - r2_score: 0.9552 - val_loss: 0.0040 - val_r2_score: 0.8484\n",
      "Epoch 65/300\n",
      "759/761 [============================>.] - ETA: 0s - loss: 0.0062 - r2_score: 0.9671\n",
      "Epoch 65: val_loss did not improve from 0.00252\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0062 - r2_score: 0.9292 - val_loss: 0.0034 - val_r2_score: 0.9810\n",
      "Epoch 66/300\n",
      "761/761 [==============================] - ETA: 0s - loss: 0.0059 - r2_score: 0.9150\n",
      "Epoch 66: val_loss did not improve from 0.00252\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0059 - r2_score: 0.9150 - val_loss: 0.0055 - val_r2_score: 0.9644\n",
      "Epoch 67/300\n",
      "758/761 [============================>.] - ETA: 0s - loss: 0.0062 - r2_score: 0.9346\n",
      "Epoch 67: val_loss did not improve from 0.00252\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0062 - r2_score: 0.9522 - val_loss: 0.0039 - val_r2_score: 0.8345\n",
      "Epoch 68/300\n",
      "760/761 [============================>.] - ETA: 0s - loss: 0.0060 - r2_score: 0.9640\n",
      "Epoch 68: val_loss did not improve from 0.00252\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0060 - r2_score: 0.9447 - val_loss: 0.0027 - val_r2_score: 0.9861\n",
      "Epoch 69/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0059 - r2_score: 0.9334\n",
      "Epoch 69: val_loss did not improve from 0.00252\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0060 - r2_score: 0.9182 - val_loss: 0.0029 - val_r2_score: 0.9915\n",
      "Epoch 70/300\n",
      "754/761 [============================>.] - ETA: 0s - loss: 0.0055 - r2_score: 0.9541\n",
      "Epoch 70: val_loss did not improve from 0.00252\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0055 - r2_score: 0.9708 - val_loss: 0.0030 - val_r2_score: 0.9755\n",
      "Epoch 71/300\n",
      "755/761 [============================>.] - ETA: 0s - loss: 0.0055 - r2_score: 0.9655\n",
      "Epoch 71: val_loss did not improve from 0.00252\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0055 - r2_score: 0.9583 - val_loss: 0.0027 - val_r2_score: 0.9875\n",
      "Epoch 72/300\n",
      "754/761 [============================>.] - ETA: 0s - loss: 0.0057 - r2_score: 0.9141\n",
      "Epoch 72: val_loss did not improve from 0.00252\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0057 - r2_score: 0.9454 - val_loss: 0.0051 - val_r2_score: 0.9612\n",
      "Epoch 73/300\n",
      "761/761 [==============================] - ETA: 0s - loss: 0.0055 - r2_score: 0.8566\n",
      "Epoch 73: val_loss did not improve from 0.00252\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0055 - r2_score: 0.8566 - val_loss: 0.0026 - val_r2_score: 0.9507\n",
      "Epoch 74/300\n",
      "756/761 [============================>.] - ETA: 0s - loss: 0.0052 - r2_score: 0.9600\n",
      "Epoch 74: val_loss did not improve from 0.00252\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0052 - r2_score: 0.9547 - val_loss: 0.0031 - val_r2_score: 0.9399\n",
      "Epoch 75/300\n",
      "757/761 [============================>.] - ETA: 0s - loss: 0.0051 - r2_score: 0.9592\n",
      "Epoch 75: val_loss improved from 0.00252 to 0.00249, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0051 - r2_score: 0.9324 - val_loss: 0.0025 - val_r2_score: 0.9773\n",
      "Epoch 76/300\n",
      "757/761 [============================>.] - ETA: 0s - loss: 0.0050 - r2_score: 0.9790\n",
      "Epoch 76: val_loss did not improve from 0.00249\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0050 - r2_score: 0.9689 - val_loss: 0.0029 - val_r2_score: 0.9812\n",
      "Epoch 77/300\n",
      "750/761 [============================>.] - ETA: 0s - loss: 0.0051 - r2_score: 0.9716\n",
      "Epoch 77: val_loss did not improve from 0.00249\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0051 - r2_score: 0.9468 - val_loss: 0.0026 - val_r2_score: 0.9721\n",
      "Epoch 78/300\n",
      "755/761 [============================>.] - ETA: 0s - loss: 0.0049 - r2_score: 0.9600\n",
      "Epoch 78: val_loss did not improve from 0.00249\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0049 - r2_score: 0.9360 - val_loss: 0.0025 - val_r2_score: 0.9641\n",
      "Epoch 79/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0049 - r2_score: 0.9509\n",
      "Epoch 79: val_loss improved from 0.00249 to 0.00202, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0049 - r2_score: 0.9373 - val_loss: 0.0020 - val_r2_score: 0.9876\n",
      "Epoch 80/300\n",
      "754/761 [============================>.] - ETA: 0s - loss: 0.0048 - r2_score: 0.9219\n",
      "Epoch 80: val_loss did not improve from 0.00202\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0048 - r2_score: 0.9505 - val_loss: 0.0026 - val_r2_score: 0.9877\n",
      "Epoch 81/300\n",
      "760/761 [============================>.] - ETA: 0s - loss: 0.0047 - r2_score: 0.9372\n",
      "Epoch 81: val_loss did not improve from 0.00202\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0047 - r2_score: 0.9665 - val_loss: 0.0022 - val_r2_score: 0.9766\n",
      "Epoch 82/300\n",
      "749/761 [============================>.] - ETA: 0s - loss: 0.0043 - r2_score: 0.9667\n",
      "Epoch 82: val_loss did not improve from 0.00202\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0043 - r2_score: 0.9334 - val_loss: 0.0045 - val_r2_score: 0.9665\n",
      "Epoch 83/300\n",
      "755/761 [============================>.] - ETA: 0s - loss: 0.0044 - r2_score: 0.9604\n",
      "Epoch 83: val_loss did not improve from 0.00202\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0044 - r2_score: 0.9501 - val_loss: 0.0042 - val_r2_score: 0.9730\n",
      "Epoch 84/300\n",
      "760/761 [============================>.] - ETA: 0s - loss: 0.0044 - r2_score: 0.9748\n",
      "Epoch 84: val_loss did not improve from 0.00202\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0044 - r2_score: 0.9767 - val_loss: 0.0025 - val_r2_score: 0.9472\n",
      "Epoch 85/300\n",
      "754/761 [============================>.] - ETA: 0s - loss: 0.0044 - r2_score: 0.9349\n",
      "Epoch 85: val_loss did not improve from 0.00202\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0044 - r2_score: 0.9723 - val_loss: 0.0028 - val_r2_score: 0.9805\n",
      "Epoch 86/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0044 - r2_score: 0.9459\n",
      "Epoch 86: val_loss did not improve from 0.00202\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0044 - r2_score: 0.9291 - val_loss: 0.0022 - val_r2_score: 0.9558\n",
      "Epoch 87/300\n",
      "758/761 [============================>.] - ETA: 0s - loss: 0.0041 - r2_score: 0.9574\n",
      "Epoch 87: val_loss did not improve from 0.00202\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0041 - r2_score: 0.9378 - val_loss: 0.0027 - val_r2_score: 0.9839\n",
      "Epoch 88/300\n",
      "754/761 [============================>.] - ETA: 0s - loss: 0.0040 - r2_score: 0.9736\n",
      "Epoch 88: val_loss did not improve from 0.00202\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0040 - r2_score: 0.9510 - val_loss: 0.0025 - val_r2_score: 0.9523\n",
      "Epoch 89/300\n",
      "759/761 [============================>.] - ETA: 0s - loss: 0.0040 - r2_score: 0.9806\n",
      "Epoch 89: val_loss improved from 0.00202 to 0.00172, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0040 - r2_score: 0.9597 - val_loss: 0.0017 - val_r2_score: 0.9860\n",
      "Epoch 90/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0039 - r2_score: 0.9820\n",
      "Epoch 90: val_loss did not improve from 0.00172\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0039 - r2_score: 0.9671 - val_loss: 0.0018 - val_r2_score: 0.9782\n",
      "Epoch 91/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0039 - r2_score: 0.9712\n",
      "Epoch 91: val_loss improved from 0.00172 to 0.00159, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0039 - r2_score: 0.9563 - val_loss: 0.0016 - val_r2_score: 0.9934\n",
      "Epoch 92/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0039 - r2_score: 0.9734\n",
      "Epoch 92: val_loss did not improve from 0.00159\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0039 - r2_score: 0.9647 - val_loss: 0.0016 - val_r2_score: 0.9523\n",
      "Epoch 93/300\n",
      "756/761 [============================>.] - ETA: 0s - loss: 0.0038 - r2_score: 0.8849\n",
      "Epoch 93: val_loss did not improve from 0.00159\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0038 - r2_score: 0.9518 - val_loss: 0.0026 - val_r2_score: 0.9781\n",
      "Epoch 94/300\n",
      "755/761 [============================>.] - ETA: 0s - loss: 0.0039 - r2_score: 0.9849\n",
      "Epoch 94: val_loss did not improve from 0.00159\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0039 - r2_score: 0.9630 - val_loss: 0.0018 - val_r2_score: 0.9903\n",
      "Epoch 95/300\n",
      "748/761 [============================>.] - ETA: 0s - loss: 0.0038 - r2_score: 0.9743\n",
      "Epoch 95: val_loss did not improve from 0.00159\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0038 - r2_score: 0.9691 - val_loss: 0.0026 - val_r2_score: 0.9626\n",
      "Epoch 96/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0035 - r2_score: 0.9697\n",
      "Epoch 96: val_loss did not improve from 0.00159\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0035 - r2_score: 0.9405 - val_loss: 0.0021 - val_r2_score: 0.9736\n",
      "Epoch 97/300\n",
      "755/761 [============================>.] - ETA: 0s - loss: 0.0036 - r2_score: 0.9693\n",
      "Epoch 97: val_loss did not improve from 0.00159\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0036 - r2_score: 0.9350 - val_loss: 0.0022 - val_r2_score: 0.8160\n",
      "Epoch 98/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0037 - r2_score: 0.9375\n",
      "Epoch 98: val_loss did not improve from 0.00159\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0037 - r2_score: 0.9172 - val_loss: 0.0022 - val_r2_score: 0.9562\n",
      "Epoch 99/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0036 - r2_score: 0.9648\n",
      "Epoch 99: val_loss did not improve from 0.00159\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0036 - r2_score: 0.9688 - val_loss: 0.0020 - val_r2_score: 0.9839\n",
      "Epoch 100/300\n",
      "751/761 [============================>.] - ETA: 0s - loss: 0.0034 - r2_score: 0.9375\n",
      "Epoch 100: val_loss improved from 0.00159 to 0.00153, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0034 - r2_score: 0.9529 - val_loss: 0.0015 - val_r2_score: 0.9856\n",
      "Epoch 101/300\n",
      "760/761 [============================>.] - ETA: 0s - loss: 0.0033 - r2_score: 0.9806\n",
      "Epoch 101: val_loss improved from 0.00153 to 0.00144, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0033 - r2_score: 0.9491 - val_loss: 0.0014 - val_r2_score: 0.9859\n",
      "Epoch 102/300\n",
      "750/761 [============================>.] - ETA: 0s - loss: 0.0035 - r2_score: 0.9638\n",
      "Epoch 102: val_loss did not improve from 0.00144\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0035 - r2_score: 0.9510 - val_loss: 0.0022 - val_r2_score: 0.9689\n",
      "Epoch 103/300\n",
      "751/761 [============================>.] - ETA: 0s - loss: 0.0033 - r2_score: 0.9843\n",
      "Epoch 103: val_loss improved from 0.00144 to 0.00132, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0033 - r2_score: 0.9776 - val_loss: 0.0013 - val_r2_score: 0.9937\n",
      "Epoch 104/300\n",
      "757/761 [============================>.] - ETA: 0s - loss: 0.0032 - r2_score: 0.9709\n",
      "Epoch 104: val_loss did not improve from 0.00132\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0032 - r2_score: 0.9367 - val_loss: 0.0016 - val_r2_score: 0.9836\n",
      "Epoch 105/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0032 - r2_score: 0.9743\n",
      "Epoch 105: val_loss did not improve from 0.00132\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0032 - r2_score: 0.9421 - val_loss: 0.0015 - val_r2_score: 0.9875\n",
      "Epoch 106/300\n",
      "757/761 [============================>.] - ETA: 0s - loss: 0.0033 - r2_score: 0.9747\n",
      "Epoch 106: val_loss did not improve from 0.00132\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0033 - r2_score: 0.9699 - val_loss: 0.0019 - val_r2_score: 0.9897\n",
      "Epoch 107/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0032 - r2_score: 0.9702\n",
      "Epoch 107: val_loss did not improve from 0.00132\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0032 - r2_score: 0.9647 - val_loss: 0.0020 - val_r2_score: 0.9926\n",
      "Epoch 108/300\n",
      "751/761 [============================>.] - ETA: 0s - loss: 0.0031 - r2_score: 0.9870\n",
      "Epoch 108: val_loss did not improve from 0.00132\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0031 - r2_score: 0.9775 - val_loss: 0.0015 - val_r2_score: 0.9807\n",
      "Epoch 109/300\n",
      "754/761 [============================>.] - ETA: 0s - loss: 0.0031 - r2_score: 0.9786\n",
      "Epoch 109: val_loss did not improve from 0.00132\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0031 - r2_score: 0.9829 - val_loss: 0.0020 - val_r2_score: 0.9789\n",
      "Epoch 110/300\n",
      "751/761 [============================>.] - ETA: 0s - loss: 0.0030 - r2_score: 0.9768\n",
      "Epoch 110: val_loss improved from 0.00132 to 0.00126, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0030 - r2_score: 0.9809 - val_loss: 0.0013 - val_r2_score: 0.9881\n",
      "Epoch 111/300\n",
      "754/761 [============================>.] - ETA: 0s - loss: 0.0031 - r2_score: 0.9758\n",
      "Epoch 111: val_loss did not improve from 0.00126\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0031 - r2_score: 0.9523 - val_loss: 0.0017 - val_r2_score: 0.9916\n",
      "Epoch 112/300\n",
      "757/761 [============================>.] - ETA: 0s - loss: 0.0029 - r2_score: 0.9800\n",
      "Epoch 112: val_loss did not improve from 0.00126\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0029 - r2_score: 0.9778 - val_loss: 0.0013 - val_r2_score: 0.9851\n",
      "Epoch 113/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0029 - r2_score: 0.9444\n",
      "Epoch 113: val_loss did not improve from 0.00126\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0029 - r2_score: 0.9857 - val_loss: 0.0017 - val_r2_score: 0.9718\n",
      "Epoch 114/300\n",
      "757/761 [============================>.] - ETA: 0s - loss: 0.0030 - r2_score: 0.9764\n",
      "Epoch 114: val_loss did not improve from 0.00126\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0030 - r2_score: 0.9399 - val_loss: 0.0038 - val_r2_score: 0.9769\n",
      "Epoch 115/300\n",
      "757/761 [============================>.] - ETA: 0s - loss: 0.0030 - r2_score: 0.9767\n",
      "Epoch 115: val_loss did not improve from 0.00126\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0030 - r2_score: 0.9804 - val_loss: 0.0013 - val_r2_score: 0.9797\n",
      "Epoch 116/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0028 - r2_score: 0.9531\n",
      "Epoch 116: val_loss did not improve from 0.00126\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0028 - r2_score: 0.9549 - val_loss: 0.0018 - val_r2_score: 0.9856\n",
      "Epoch 117/300\n",
      "754/761 [============================>.] - ETA: 0s - loss: 0.0028 - r2_score: 0.9520\n",
      "Epoch 117: val_loss did not improve from 0.00126\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0028 - r2_score: 0.9799 - val_loss: 0.0020 - val_r2_score: 0.9831\n",
      "Epoch 118/300\n",
      "757/761 [============================>.] - ETA: 0s - loss: 0.0028 - r2_score: 0.9692\n",
      "Epoch 118: val_loss did not improve from 0.00126\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0028 - r2_score: 0.9613 - val_loss: 0.0015 - val_r2_score: 0.9656\n",
      "Epoch 119/300\n",
      "751/761 [============================>.] - ETA: 0s - loss: 0.0028 - r2_score: 0.9743\n",
      "Epoch 119: val_loss improved from 0.00126 to 0.00118, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0028 - r2_score: 0.9835 - val_loss: 0.0012 - val_r2_score: 0.9940\n",
      "Epoch 120/300\n",
      "760/761 [============================>.] - ETA: 0s - loss: 0.0029 - r2_score: 0.9493\n",
      "Epoch 120: val_loss did not improve from 0.00118\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0029 - r2_score: 0.9698 - val_loss: 0.0020 - val_r2_score: 0.9851\n",
      "Epoch 121/300\n",
      "760/761 [============================>.] - ETA: 0s - loss: 0.0027 - r2_score: 0.9765\n",
      "Epoch 121: val_loss did not improve from 0.00118\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0027 - r2_score: 0.9146 - val_loss: 0.0029 - val_r2_score: 0.9832\n",
      "Epoch 122/300\n",
      "756/761 [============================>.] - ETA: 0s - loss: 0.0027 - r2_score: 0.9713\n",
      "Epoch 122: val_loss did not improve from 0.00118\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0027 - r2_score: 0.9719 - val_loss: 0.0013 - val_r2_score: 0.9881\n",
      "Epoch 123/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0028 - r2_score: 0.9514\n",
      "Epoch 123: val_loss did not improve from 0.00118\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0028 - r2_score: 0.9460 - val_loss: 0.0020 - val_r2_score: 0.9622\n",
      "Epoch 124/300\n",
      "754/761 [============================>.] - ETA: 0s - loss: 0.0026 - r2_score: 0.9783\n",
      "Epoch 124: val_loss did not improve from 0.00118\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0026 - r2_score: 0.9635 - val_loss: 0.0014 - val_r2_score: 0.9944\n",
      "Epoch 125/300\n",
      "760/761 [============================>.] - ETA: 0s - loss: 0.0027 - r2_score: 0.9696\n",
      "Epoch 125: val_loss did not improve from 0.00118\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0027 - r2_score: 0.9684 - val_loss: 0.0013 - val_r2_score: 0.9876\n",
      "Epoch 126/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0027 - r2_score: 0.9220\n",
      "Epoch 126: val_loss did not improve from 0.00118\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0027 - r2_score: 0.9492 - val_loss: 0.0015 - val_r2_score: 0.9868\n",
      "Epoch 127/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0026 - r2_score: 0.9813\n",
      "Epoch 127: val_loss did not improve from 0.00118\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0026 - r2_score: 0.9669 - val_loss: 0.0013 - val_r2_score: 0.9949\n",
      "Epoch 128/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0027 - r2_score: 0.9443\n",
      "Epoch 128: val_loss did not improve from 0.00118\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0027 - r2_score: 0.9524 - val_loss: 0.0017 - val_r2_score: 0.9774\n",
      "Epoch 129/300\n",
      "755/761 [============================>.] - ETA: 0s - loss: 0.0026 - r2_score: 0.9833\n",
      "Epoch 129: val_loss did not improve from 0.00118\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0026 - r2_score: 0.9875 - val_loss: 0.0012 - val_r2_score: 0.9893\n",
      "Epoch 130/300\n",
      "759/761 [============================>.] - ETA: 0s - loss: 0.0026 - r2_score: 0.9699\n",
      "Epoch 130: val_loss improved from 0.00118 to 0.00114, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0026 - r2_score: 0.9848 - val_loss: 0.0011 - val_r2_score: 0.9795\n",
      "Epoch 131/300\n",
      "754/761 [============================>.] - ETA: 0s - loss: 0.0026 - r2_score: 0.9183\n",
      "Epoch 131: val_loss did not improve from 0.00114\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0026 - r2_score: 0.9753 - val_loss: 0.0013 - val_r2_score: 0.9924\n",
      "Epoch 132/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0025 - r2_score: 0.9631\n",
      "Epoch 132: val_loss did not improve from 0.00114\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0025 - r2_score: 0.9872 - val_loss: 0.0012 - val_r2_score: 0.9593\n",
      "Epoch 133/300\n",
      "760/761 [============================>.] - ETA: 0s - loss: 0.0026 - r2_score: 0.9573\n",
      "Epoch 133: val_loss did not improve from 0.00114\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0026 - r2_score: 0.9890 - val_loss: 0.0012 - val_r2_score: 0.9890\n",
      "Epoch 134/300\n",
      "761/761 [==============================] - ETA: 0s - loss: 0.0025 - r2_score: 0.9753\n",
      "Epoch 134: val_loss did not improve from 0.00114\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0025 - r2_score: 0.9753 - val_loss: 0.0014 - val_r2_score: 0.9711\n",
      "Epoch 135/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0026 - r2_score: 0.9703\n",
      "Epoch 135: val_loss improved from 0.00114 to 0.00107, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0025 - r2_score: 0.9818 - val_loss: 0.0011 - val_r2_score: 0.9965\n",
      "Epoch 136/300\n",
      "758/761 [============================>.] - ETA: 0s - loss: 0.0026 - r2_score: 0.9828\n",
      "Epoch 136: val_loss did not improve from 0.00107\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0026 - r2_score: 0.9891 - val_loss: 0.0014 - val_r2_score: 0.9746\n",
      "Epoch 137/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0025 - r2_score: 0.9865\n",
      "Epoch 137: val_loss did not improve from 0.00107\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0025 - r2_score: 0.9733 - val_loss: 0.0012 - val_r2_score: 0.9964\n",
      "Epoch 138/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0025 - r2_score: 0.9807\n",
      "Epoch 138: val_loss improved from 0.00107 to 0.00102, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0025 - r2_score: 0.9725 - val_loss: 0.0010 - val_r2_score: 0.9643\n",
      "Epoch 139/300\n",
      "761/761 [==============================] - ETA: 0s - loss: 0.0024 - r2_score: 0.9461\n",
      "Epoch 139: val_loss did not improve from 0.00102\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0024 - r2_score: 0.9461 - val_loss: 0.0012 - val_r2_score: 0.9923\n",
      "Epoch 140/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0025 - r2_score: 0.9899\n",
      "Epoch 140: val_loss improved from 0.00102 to 0.00101, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0025 - r2_score: 0.9831 - val_loss: 0.0010 - val_r2_score: 0.9976\n",
      "Epoch 141/300\n",
      "750/761 [============================>.] - ETA: 0s - loss: 0.0025 - r2_score: 0.9543\n",
      "Epoch 141: val_loss did not improve from 0.00101\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0025 - r2_score: 0.9828 - val_loss: 0.0012 - val_r2_score: 0.9777\n",
      "Epoch 142/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0024 - r2_score: 0.9771\n",
      "Epoch 142: val_loss did not improve from 0.00101\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0024 - r2_score: 0.9848 - val_loss: 0.0011 - val_r2_score: 0.9933\n",
      "Epoch 143/300\n",
      "751/761 [============================>.] - ETA: 0s - loss: 0.0024 - r2_score: 0.9661\n",
      "Epoch 143: val_loss did not improve from 0.00101\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0024 - r2_score: 0.9610 - val_loss: 0.0015 - val_r2_score: 0.9929\n",
      "Epoch 144/300\n",
      "758/761 [============================>.] - ETA: 0s - loss: 0.0025 - r2_score: 0.9532\n",
      "Epoch 144: val_loss did not improve from 0.00101\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0025 - r2_score: 0.9820 - val_loss: 0.0011 - val_r2_score: 0.9944\n",
      "Epoch 145/300\n",
      "759/761 [============================>.] - ETA: 0s - loss: 0.0024 - r2_score: 0.9771\n",
      "Epoch 145: val_loss did not improve from 0.00101\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0024 - r2_score: 0.9712 - val_loss: 0.0011 - val_r2_score: 0.9912\n",
      "Epoch 146/300\n",
      "754/761 [============================>.] - ETA: 0s - loss: 0.0024 - r2_score: 0.9786\n",
      "Epoch 146: val_loss improved from 0.00101 to 0.00101, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0024 - r2_score: 0.9837 - val_loss: 0.0010 - val_r2_score: 0.9966\n",
      "Epoch 147/300\n",
      "751/761 [============================>.] - ETA: 0s - loss: 0.0024 - r2_score: 0.9788\n",
      "Epoch 147: val_loss did not improve from 0.00101\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0024 - r2_score: 0.9482 - val_loss: 0.0011 - val_r2_score: 0.9947\n",
      "Epoch 148/300\n",
      "761/761 [==============================] - ETA: 0s - loss: 0.0024 - r2_score: 0.9578\n",
      "Epoch 148: val_loss improved from 0.00101 to 0.00093, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0024 - r2_score: 0.9578 - val_loss: 9.3192e-04 - val_r2_score: 0.9886\n",
      "Epoch 149/300\n",
      "758/761 [============================>.] - ETA: 0s - loss: 0.0024 - r2_score: 0.9770\n",
      "Epoch 149: val_loss did not improve from 0.00093\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0024 - r2_score: 0.9823 - val_loss: 0.0012 - val_r2_score: 0.9810\n",
      "Epoch 150/300\n",
      "755/761 [============================>.] - ETA: 0s - loss: 0.0024 - r2_score: 0.9830\n",
      "Epoch 150: val_loss did not improve from 0.00093\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0024 - r2_score: 0.9827 - val_loss: 0.0010 - val_r2_score: 0.9896\n",
      "Epoch 151/300\n",
      "760/761 [============================>.] - ETA: 0s - loss: 0.0023 - r2_score: 0.9753\n",
      "Epoch 151: val_loss did not improve from 0.00093\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0023 - r2_score: 0.9342 - val_loss: 0.0012 - val_r2_score: 0.9820\n",
      "Epoch 152/300\n",
      "761/761 [==============================] - ETA: 0s - loss: 0.0024 - r2_score: 0.9842\n",
      "Epoch 152: val_loss did not improve from 0.00093\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0024 - r2_score: 0.9842 - val_loss: 0.0017 - val_r2_score: 0.9814\n",
      "Epoch 153/300\n",
      "758/761 [============================>.] - ETA: 0s - loss: 0.0024 - r2_score: 0.9818\n",
      "Epoch 153: val_loss did not improve from 0.00093\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0023 - r2_score: 0.9686 - val_loss: 0.0012 - val_r2_score: 0.9959\n",
      "Epoch 154/300\n",
      "761/761 [==============================] - ETA: 0s - loss: 0.0024 - r2_score: 0.9798\n",
      "Epoch 154: val_loss did not improve from 0.00093\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0024 - r2_score: 0.9798 - val_loss: 0.0011 - val_r2_score: 0.9967\n",
      "Epoch 155/300\n",
      "761/761 [==============================] - ETA: 0s - loss: 0.0023 - r2_score: 0.9431\n",
      "Epoch 155: val_loss did not improve from 0.00093\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0023 - r2_score: 0.9431 - val_loss: 0.0010 - val_r2_score: 0.9736\n",
      "Epoch 156/300\n",
      "749/761 [============================>.] - ETA: 0s - loss: 0.0024 - r2_score: 0.9638\n",
      "Epoch 156: val_loss did not improve from 0.00093\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0024 - r2_score: 0.9753 - val_loss: 9.7854e-04 - val_r2_score: 0.9915\n",
      "Epoch 157/300\n",
      "760/761 [============================>.] - ETA: 0s - loss: 0.0023 - r2_score: 0.9647\n",
      "Epoch 157: val_loss did not improve from 0.00093\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0023 - r2_score: 0.9803 - val_loss: 0.0010 - val_r2_score: 0.9972\n",
      "Epoch 158/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0023 - r2_score: 0.9834\n",
      "Epoch 158: val_loss improved from 0.00093 to 0.00093, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0023 - r2_score: 0.9724 - val_loss: 9.3019e-04 - val_r2_score: 0.9885\n",
      "Epoch 159/300\n",
      "760/761 [============================>.] - ETA: 0s - loss: 0.0023 - r2_score: 0.9647\n",
      "Epoch 159: val_loss did not improve from 0.00093\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0023 - r2_score: 0.9714 - val_loss: 0.0011 - val_r2_score: 0.9847\n",
      "Epoch 160/300\n",
      "756/761 [============================>.] - ETA: 0s - loss: 0.0023 - r2_score: 0.9776\n",
      "Epoch 160: val_loss did not improve from 0.00093\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0023 - r2_score: 0.9618 - val_loss: 9.7246e-04 - val_r2_score: 0.9932\n",
      "Epoch 161/300\n",
      "760/761 [============================>.] - ETA: 0s - loss: 0.0023 - r2_score: 0.9748\n",
      "Epoch 161: val_loss did not improve from 0.00093\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0023 - r2_score: 0.9822 - val_loss: 0.0012 - val_r2_score: 0.9651\n",
      "Epoch 162/300\n",
      "750/761 [============================>.] - ETA: 0s - loss: 0.0023 - r2_score: 0.9830\n",
      "Epoch 162: val_loss improved from 0.00093 to 0.00091, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0023 - r2_score: 0.9808 - val_loss: 9.1383e-04 - val_r2_score: 0.9936\n",
      "Epoch 163/300\n",
      "755/761 [============================>.] - ETA: 0s - loss: 0.0023 - r2_score: 0.9824\n",
      "Epoch 163: val_loss did not improve from 0.00091\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0023 - r2_score: 0.9781 - val_loss: 0.0011 - val_r2_score: 0.9970\n",
      "Epoch 164/300\n",
      "760/761 [============================>.] - ETA: 0s - loss: 0.0023 - r2_score: 0.9780\n",
      "Epoch 164: val_loss did not improve from 0.00091\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0023 - r2_score: 0.9743 - val_loss: 9.4984e-04 - val_r2_score: 0.9854\n",
      "Epoch 165/300\n",
      "756/761 [============================>.] - ETA: 0s - loss: 0.0022 - r2_score: 0.9854\n",
      "Epoch 165: val_loss did not improve from 0.00091\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9448 - val_loss: 0.0010 - val_r2_score: 0.9878\n",
      "Epoch 166/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0023 - r2_score: 0.9653\n",
      "Epoch 166: val_loss did not improve from 0.00091\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0023 - r2_score: 0.9794 - val_loss: 0.0011 - val_r2_score: 0.9927\n",
      "Epoch 167/300\n",
      "755/761 [============================>.] - ETA: 0s - loss: 0.0022 - r2_score: 0.9641\n",
      "Epoch 167: val_loss did not improve from 0.00091\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9843 - val_loss: 9.9281e-04 - val_r2_score: 0.9940\n",
      "Epoch 168/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0022 - r2_score: 0.9834\n",
      "Epoch 168: val_loss did not improve from 0.00091\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9835 - val_loss: 9.1612e-04 - val_r2_score: 0.9953\n",
      "Epoch 169/300\n",
      "757/761 [============================>.] - ETA: 0s - loss: 0.0023 - r2_score: 0.9887\n",
      "Epoch 169: val_loss did not improve from 0.00091\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0023 - r2_score: 0.9772 - val_loss: 9.7755e-04 - val_r2_score: 0.9885\n",
      "Epoch 170/300\n",
      "750/761 [============================>.] - ETA: 0s - loss: 0.0023 - r2_score: 0.9834\n",
      "Epoch 170: val_loss did not improve from 0.00091\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0023 - r2_score: 0.9790 - val_loss: 0.0010 - val_r2_score: 0.9970\n",
      "Epoch 171/300\n",
      "755/761 [============================>.] - ETA: 0s - loss: 0.0022 - r2_score: 0.9762\n",
      "Epoch 171: val_loss did not improve from 0.00091\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9794 - val_loss: 9.5131e-04 - val_r2_score: 0.9788\n",
      "Epoch 172/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0022 - r2_score: 0.9852\n",
      "Epoch 172: val_loss improved from 0.00091 to 0.00091, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9825 - val_loss: 9.0841e-04 - val_r2_score: 0.9967\n",
      "Epoch 173/300\n",
      "756/761 [============================>.] - ETA: 0s - loss: 0.0022 - r2_score: 0.9783\n",
      "Epoch 173: val_loss did not improve from 0.00091\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9889 - val_loss: 9.3366e-04 - val_r2_score: 0.9811\n",
      "Epoch 174/300\n",
      "757/761 [============================>.] - ETA: 0s - loss: 0.0022 - r2_score: 0.9893\n",
      "Epoch 174: val_loss improved from 0.00091 to 0.00089, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9877 - val_loss: 8.9441e-04 - val_r2_score: 0.9908\n",
      "Epoch 175/300\n",
      "755/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9705\n",
      "Epoch 175: val_loss did not improve from 0.00089\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9737 - val_loss: 9.4015e-04 - val_r2_score: 0.9915\n",
      "Epoch 176/300\n",
      "751/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9875\n",
      "Epoch 176: val_loss did not improve from 0.00089\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9638 - val_loss: 9.2738e-04 - val_r2_score: 0.9880\n",
      "Epoch 177/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0022 - r2_score: 0.9772\n",
      "Epoch 177: val_loss improved from 0.00089 to 0.00088, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9624 - val_loss: 8.7762e-04 - val_r2_score: 0.9927\n",
      "Epoch 178/300\n",
      "758/761 [============================>.] - ETA: 0s - loss: 0.0022 - r2_score: 0.9771\n",
      "Epoch 178: val_loss did not improve from 0.00088\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9708 - val_loss: 0.0011 - val_r2_score: 0.9894\n",
      "Epoch 179/300\n",
      "750/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9854\n",
      "Epoch 179: val_loss did not improve from 0.00088\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9729 - val_loss: 8.7883e-04 - val_r2_score: 0.9862\n",
      "Epoch 180/300\n",
      "759/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9650\n",
      "Epoch 180: val_loss did not improve from 0.00088\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9859 - val_loss: 8.9652e-04 - val_r2_score: 0.9951\n",
      "Epoch 181/300\n",
      "755/761 [============================>.] - ETA: 0s - loss: 0.0022 - r2_score: 0.9826\n",
      "Epoch 181: val_loss improved from 0.00088 to 0.00087, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9901 - val_loss: 8.6760e-04 - val_r2_score: 0.9971\n",
      "Epoch 182/300\n",
      "760/761 [============================>.] - ETA: 0s - loss: 0.0022 - r2_score: 0.9767\n",
      "Epoch 182: val_loss did not improve from 0.00087\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9858 - val_loss: 9.4385e-04 - val_r2_score: 0.9964\n",
      "Epoch 183/300\n",
      "756/761 [============================>.] - ETA: 0s - loss: 0.0022 - r2_score: 0.9886\n",
      "Epoch 183: val_loss did not improve from 0.00087\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9642 - val_loss: 9.4540e-04 - val_r2_score: 0.9799\n",
      "Epoch 184/300\n",
      "756/761 [============================>.] - ETA: 0s - loss: 0.0022 - r2_score: 0.9772\n",
      "Epoch 184: val_loss did not improve from 0.00087\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9689 - val_loss: 9.2169e-04 - val_r2_score: 0.9901\n",
      "Epoch 185/300\n",
      "758/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9900\n",
      "Epoch 185: val_loss did not improve from 0.00087\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9835 - val_loss: 8.8206e-04 - val_r2_score: 0.9971\n",
      "Epoch 186/300\n",
      "755/761 [============================>.] - ETA: 0s - loss: 0.0022 - r2_score: 0.9817\n",
      "Epoch 186: val_loss did not improve from 0.00087\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9850 - val_loss: 0.0010 - val_r2_score: 0.9918\n",
      "Epoch 187/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0022 - r2_score: 0.9537\n",
      "Epoch 187: val_loss did not improve from 0.00087\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9825 - val_loss: 8.9354e-04 - val_r2_score: 0.9878\n",
      "Epoch 188/300\n",
      "754/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9660\n",
      "Epoch 188: val_loss did not improve from 0.00087\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9718 - val_loss: 8.9133e-04 - val_r2_score: 0.9974\n",
      "Epoch 189/300\n",
      "754/761 [============================>.] - ETA: 0s - loss: 0.0022 - r2_score: 0.9820\n",
      "Epoch 189: val_loss did not improve from 0.00087\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9817 - val_loss: 9.2832e-04 - val_r2_score: 0.9960\n",
      "Epoch 190/300\n",
      "751/761 [============================>.] - ETA: 0s - loss: 0.0022 - r2_score: 0.9829\n",
      "Epoch 190: val_loss did not improve from 0.00087\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9655 - val_loss: 9.3203e-04 - val_r2_score: 0.9973\n",
      "Epoch 191/300\n",
      "749/761 [============================>.] - ETA: 0s - loss: 0.0022 - r2_score: 0.9789\n",
      "Epoch 191: val_loss did not improve from 0.00087\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9662 - val_loss: 8.6777e-04 - val_r2_score: 0.9950\n",
      "Epoch 192/300\n",
      "750/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9809\n",
      "Epoch 192: val_loss did not improve from 0.00087\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9796 - val_loss: 8.9235e-04 - val_r2_score: 0.9906\n",
      "Epoch 193/300\n",
      "756/761 [============================>.] - ETA: 0s - loss: 0.0022 - r2_score: 0.9799\n",
      "Epoch 193: val_loss did not improve from 0.00087\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9901 - val_loss: 8.8597e-04 - val_r2_score: 0.9962\n",
      "Epoch 194/300\n",
      "750/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9765\n",
      "Epoch 194: val_loss did not improve from 0.00087\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9669 - val_loss: 9.2465e-04 - val_r2_score: 0.9920\n",
      "Epoch 195/300\n",
      "751/761 [============================>.] - ETA: 0s - loss: 0.0022 - r2_score: 0.9835\n",
      "Epoch 195: val_loss improved from 0.00087 to 0.00086, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9821 - val_loss: 8.6264e-04 - val_r2_score: 0.9733\n",
      "Epoch 196/300\n",
      "750/761 [============================>.] - ETA: 0s - loss: 0.0022 - r2_score: 0.9766\n",
      "Epoch 196: val_loss did not improve from 0.00086\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9899 - val_loss: 8.8974e-04 - val_r2_score: 0.9943\n",
      "Epoch 197/300\n",
      "759/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9741\n",
      "Epoch 197: val_loss did not improve from 0.00086\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9812 - val_loss: 8.7126e-04 - val_r2_score: 0.9951\n",
      "Epoch 198/300\n",
      "759/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9836\n",
      "Epoch 198: val_loss did not improve from 0.00086\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9841 - val_loss: 8.7115e-04 - val_r2_score: 0.9929\n",
      "Epoch 199/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9855\n",
      "Epoch 199: val_loss did not improve from 0.00086\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9590 - val_loss: 8.7171e-04 - val_r2_score: 0.9831\n",
      "Epoch 200/300\n",
      "759/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9551\n",
      "Epoch 200: val_loss improved from 0.00086 to 0.00085, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9777 - val_loss: 8.5022e-04 - val_r2_score: 0.9894\n",
      "Epoch 201/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9772\n",
      "Epoch 201: val_loss did not improve from 0.00085\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9249 - val_loss: 8.8579e-04 - val_r2_score: 0.9936\n",
      "Epoch 202/300\n",
      "757/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9857\n",
      "Epoch 202: val_loss did not improve from 0.00085\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9854 - val_loss: 8.5885e-04 - val_r2_score: 0.9880\n",
      "Epoch 203/300\n",
      "761/761 [==============================] - ETA: 0s - loss: 0.0022 - r2_score: 0.9777\n",
      "Epoch 203: val_loss did not improve from 0.00085\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9777 - val_loss: 8.5107e-04 - val_r2_score: 0.9990\n",
      "Epoch 204/300\n",
      "757/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9877\n",
      "Epoch 204: val_loss did not improve from 0.00085\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9757 - val_loss: 8.6397e-04 - val_r2_score: 0.9661\n",
      "Epoch 205/300\n",
      "749/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9770\n",
      "Epoch 205: val_loss did not improve from 0.00085\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9544 - val_loss: 8.6466e-04 - val_r2_score: 0.9873\n",
      "Epoch 206/300\n",
      "754/761 [============================>.] - ETA: 0s - loss: 0.0022 - r2_score: 0.9853\n",
      "Epoch 206: val_loss improved from 0.00085 to 0.00085, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9386 - val_loss: 8.5022e-04 - val_r2_score: 0.9981\n",
      "Epoch 207/300\n",
      "761/761 [==============================] - ETA: 0s - loss: 0.0021 - r2_score: 0.9714\n",
      "Epoch 207: val_loss improved from 0.00085 to 0.00085, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9714 - val_loss: 8.4833e-04 - val_r2_score: 0.9908\n",
      "Epoch 208/300\n",
      "749/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9877\n",
      "Epoch 208: val_loss did not improve from 0.00085\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9735 - val_loss: 9.1483e-04 - val_r2_score: 0.9930\n",
      "Epoch 209/300\n",
      "757/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9766\n",
      "Epoch 209: val_loss did not improve from 0.00085\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9868 - val_loss: 8.6268e-04 - val_r2_score: 0.9974\n",
      "Epoch 210/300\n",
      "755/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9623\n",
      "Epoch 210: val_loss did not improve from 0.00085\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9867 - val_loss: 8.5159e-04 - val_r2_score: 0.9923\n",
      "Epoch 211/300\n",
      "756/761 [============================>.] - ETA: 0s - loss: 0.0022 - r2_score: 0.9868\n",
      "Epoch 211: val_loss did not improve from 0.00085\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9785 - val_loss: 8.5678e-04 - val_r2_score: 0.9963\n",
      "Epoch 212/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9882\n",
      "Epoch 212: val_loss did not improve from 0.00085\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9825 - val_loss: 8.6488e-04 - val_r2_score: 0.9919\n",
      "Epoch 213/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9741\n",
      "Epoch 213: val_loss did not improve from 0.00085\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9723 - val_loss: 8.5016e-04 - val_r2_score: 0.9912\n",
      "Epoch 214/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9837\n",
      "Epoch 214: val_loss did not improve from 0.00085\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9827 - val_loss: 8.5325e-04 - val_r2_score: 0.9884\n",
      "Epoch 215/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9876\n",
      "Epoch 215: val_loss did not improve from 0.00085\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9796 - val_loss: 8.6512e-04 - val_r2_score: 0.9965\n",
      "Epoch 216/300\n",
      "750/761 [============================>.] - ETA: 0s - loss: 0.0020 - r2_score: 0.9660\n",
      "Epoch 216: val_loss did not improve from 0.00085\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0020 - r2_score: 0.9903 - val_loss: 8.6125e-04 - val_r2_score: 0.9939\n",
      "Epoch 217/300\n",
      "750/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9855\n",
      "Epoch 217: val_loss did not improve from 0.00085\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9491 - val_loss: 8.5027e-04 - val_r2_score: 0.9903\n",
      "Epoch 218/300\n",
      "751/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9902\n",
      "Epoch 218: val_loss improved from 0.00085 to 0.00084, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9830 - val_loss: 8.4382e-04 - val_r2_score: 0.9762\n",
      "Epoch 219/300\n",
      "761/761 [==============================] - ETA: 0s - loss: 0.0021 - r2_score: 0.9828\n",
      "Epoch 219: val_loss did not improve from 0.00084\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9828 - val_loss: 8.5733e-04 - val_r2_score: 0.9807\n",
      "Epoch 220/300\n",
      "756/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9495\n",
      "Epoch 220: val_loss improved from 0.00084 to 0.00084, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9413 - val_loss: 8.4259e-04 - val_r2_score: 0.9923\n",
      "Epoch 221/300\n",
      "754/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9777\n",
      "Epoch 221: val_loss did not improve from 0.00084\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9569 - val_loss: 8.4823e-04 - val_r2_score: 0.9967\n",
      "Epoch 222/300\n",
      "758/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9827\n",
      "Epoch 222: val_loss did not improve from 0.00084\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9883 - val_loss: 8.4535e-04 - val_r2_score: 0.9875\n",
      "Epoch 223/300\n",
      "756/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9852\n",
      "Epoch 223: val_loss improved from 0.00084 to 0.00084, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9864 - val_loss: 8.4212e-04 - val_r2_score: 0.9891\n",
      "Epoch 224/300\n",
      "757/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9837\n",
      "Epoch 224: val_loss did not improve from 0.00084\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9880 - val_loss: 8.4917e-04 - val_r2_score: 0.9954\n",
      "Epoch 225/300\n",
      "751/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9851\n",
      "Epoch 225: val_loss improved from 0.00084 to 0.00084, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9808 - val_loss: 8.3826e-04 - val_r2_score: 0.9983\n",
      "Epoch 226/300\n",
      "756/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9759\n",
      "Epoch 226: val_loss did not improve from 0.00084\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9877 - val_loss: 8.4560e-04 - val_r2_score: 0.9960\n",
      "Epoch 227/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9646\n",
      "Epoch 227: val_loss did not improve from 0.00084\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9739 - val_loss: 8.4985e-04 - val_r2_score: 0.9960\n",
      "Epoch 228/300\n",
      "750/761 [============================>.] - ETA: 0s - loss: 0.0020 - r2_score: 0.9811\n",
      "Epoch 228: val_loss did not improve from 0.00084\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0020 - r2_score: 0.9157 - val_loss: 8.4174e-04 - val_r2_score: 0.9968\n",
      "Epoch 229/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9712\n",
      "Epoch 229: val_loss improved from 0.00084 to 0.00084, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9706 - val_loss: 8.3771e-04 - val_r2_score: 0.9846\n",
      "Epoch 230/300\n",
      "757/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9587\n",
      "Epoch 230: val_loss did not improve from 0.00084\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9821 - val_loss: 8.3878e-04 - val_r2_score: 0.9883\n",
      "Epoch 231/300\n",
      "761/761 [==============================] - ETA: 0s - loss: 0.0021 - r2_score: 0.9511\n",
      "Epoch 231: val_loss did not improve from 0.00084\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9511 - val_loss: 8.5034e-04 - val_r2_score: 0.9927\n",
      "Epoch 232/300\n",
      "760/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9624\n",
      "Epoch 232: val_loss did not improve from 0.00084\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9786 - val_loss: 8.4632e-04 - val_r2_score: 0.9856\n",
      "Epoch 233/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9789\n",
      "Epoch 233: val_loss improved from 0.00084 to 0.00083, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9716 - val_loss: 8.3355e-04 - val_r2_score: 0.9891\n",
      "Epoch 234/300\n",
      "760/761 [============================>.] - ETA: 0s - loss: 0.0020 - r2_score: 0.9740\n",
      "Epoch 234: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0020 - r2_score: 0.9886 - val_loss: 8.3775e-04 - val_r2_score: 0.9972\n",
      "Epoch 235/300\n",
      "758/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9827\n",
      "Epoch 235: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9807 - val_loss: 8.3521e-04 - val_r2_score: 0.8884\n",
      "Epoch 236/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0022 - r2_score: 0.9781\n",
      "Epoch 236: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9878 - val_loss: 8.4532e-04 - val_r2_score: 0.9925\n",
      "Epoch 237/300\n",
      "754/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9829\n",
      "Epoch 237: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9803 - val_loss: 8.3786e-04 - val_r2_score: 0.9867\n",
      "Epoch 238/300\n",
      "757/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9747\n",
      "Epoch 238: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9720 - val_loss: 8.4148e-04 - val_r2_score: 0.9842\n",
      "Epoch 239/300\n",
      "750/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9833\n",
      "Epoch 239: val_loss improved from 0.00083 to 0.00083, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9856 - val_loss: 8.3261e-04 - val_r2_score: 0.9796\n",
      "Epoch 240/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9837\n",
      "Epoch 240: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9558 - val_loss: 8.3544e-04 - val_r2_score: 0.9967\n",
      "Epoch 241/300\n",
      "760/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9858\n",
      "Epoch 241: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9774 - val_loss: 8.4517e-04 - val_r2_score: 0.9957\n",
      "Epoch 242/300\n",
      "761/761 [==============================] - ETA: 0s - loss: 0.0021 - r2_score: 0.9844\n",
      "Epoch 242: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9844 - val_loss: 8.3666e-04 - val_r2_score: 0.9950\n",
      "Epoch 243/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9301\n",
      "Epoch 243: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9817 - val_loss: 8.3843e-04 - val_r2_score: 0.9976\n",
      "Epoch 244/300\n",
      "760/761 [============================>.] - ETA: 0s - loss: 0.0022 - r2_score: 0.9495\n",
      "Epoch 244: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9882 - val_loss: 8.4852e-04 - val_r2_score: 0.9655\n",
      "Epoch 245/300\n",
      "757/761 [============================>.] - ETA: 0s - loss: 0.0022 - r2_score: 0.9869\n",
      "Epoch 245: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9655 - val_loss: 8.3639e-04 - val_r2_score: 0.9949\n",
      "Epoch 246/300\n",
      "757/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9632\n",
      "Epoch 246: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9525 - val_loss: 8.3951e-04 - val_r2_score: 0.9971\n",
      "Epoch 247/300\n",
      "748/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9861\n",
      "Epoch 247: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9706 - val_loss: 8.4144e-04 - val_r2_score: 0.9927\n",
      "Epoch 248/300\n",
      "761/761 [==============================] - ETA: 0s - loss: 0.0022 - r2_score: 0.9683\n",
      "Epoch 248: val_loss improved from 0.00083 to 0.00083, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9683 - val_loss: 8.3231e-04 - val_r2_score: 0.9933\n",
      "Epoch 249/300\n",
      "760/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9846\n",
      "Epoch 249: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9731 - val_loss: 8.3503e-04 - val_r2_score: 0.9880\n",
      "Epoch 250/300\n",
      "759/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9644\n",
      "Epoch 250: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9471 - val_loss: 8.3714e-04 - val_r2_score: 0.9940\n",
      "Epoch 251/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9818\n",
      "Epoch 251: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9660 - val_loss: 8.3926e-04 - val_r2_score: 0.9984\n",
      "Epoch 252/300\n",
      "758/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9839\n",
      "Epoch 252: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9840 - val_loss: 8.4057e-04 - val_r2_score: 0.9816\n",
      "Epoch 253/300\n",
      "756/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9503\n",
      "Epoch 253: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9793 - val_loss: 8.3514e-04 - val_r2_score: 0.9805\n",
      "Epoch 254/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9700\n",
      "Epoch 254: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9879 - val_loss: 8.3810e-04 - val_r2_score: 0.9974\n",
      "Epoch 255/300\n",
      "759/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9775\n",
      "Epoch 255: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9595 - val_loss: 8.3704e-04 - val_r2_score: 0.9955\n",
      "Epoch 256/300\n",
      "756/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9833\n",
      "Epoch 256: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9719 - val_loss: 8.3459e-04 - val_r2_score: 0.9811\n",
      "Epoch 257/300\n",
      "755/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9742\n",
      "Epoch 257: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9647 - val_loss: 8.3432e-04 - val_r2_score: 0.9957\n",
      "Epoch 258/300\n",
      "757/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9786\n",
      "Epoch 258: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9615 - val_loss: 8.4332e-04 - val_r2_score: 0.9919\n",
      "Epoch 259/300\n",
      "759/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9713\n",
      "Epoch 259: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9848 - val_loss: 8.3663e-04 - val_r2_score: 0.9943\n",
      "Epoch 260/300\n",
      "750/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9820\n",
      "Epoch 260: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9435 - val_loss: 8.3657e-04 - val_r2_score: 0.9985\n",
      "Epoch 261/300\n",
      "750/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9757\n",
      "Epoch 261: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9825 - val_loss: 8.3549e-04 - val_r2_score: 0.9908\n",
      "Epoch 262/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9561\n",
      "Epoch 262: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9754 - val_loss: 8.3811e-04 - val_r2_score: 0.9876\n",
      "Epoch 263/300\n",
      "761/761 [==============================] - ETA: 0s - loss: 0.0021 - r2_score: 0.9814\n",
      "Epoch 263: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9814 - val_loss: 8.3405e-04 - val_r2_score: 0.9874\n",
      "Epoch 264/300\n",
      "756/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9815\n",
      "Epoch 264: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9778 - val_loss: 8.3771e-04 - val_r2_score: 0.9974\n",
      "Epoch 265/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0020 - r2_score: 0.9832\n",
      "Epoch 265: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0020 - r2_score: 0.9741 - val_loss: 8.3395e-04 - val_r2_score: 0.9972\n",
      "Epoch 266/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9692\n",
      "Epoch 266: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9638 - val_loss: 8.3557e-04 - val_r2_score: 0.9957\n",
      "Epoch 267/300\n",
      "749/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9797\n",
      "Epoch 267: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9693 - val_loss: 8.3649e-04 - val_r2_score: 0.9972\n",
      "Epoch 268/300\n",
      "757/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9696\n",
      "Epoch 268: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9708 - val_loss: 8.3510e-04 - val_r2_score: 0.9939\n",
      "Epoch 269/300\n",
      "750/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9567\n",
      "Epoch 269: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9764 - val_loss: 8.3860e-04 - val_r2_score: 0.9935\n",
      "Epoch 270/300\n",
      "759/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9848\n",
      "Epoch 270: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9722 - val_loss: 8.4361e-04 - val_r2_score: 0.9970\n",
      "Epoch 271/300\n",
      "756/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9838\n",
      "Epoch 271: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9718 - val_loss: 8.4674e-04 - val_r2_score: 0.9964\n",
      "Epoch 272/300\n",
      "750/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9740\n",
      "Epoch 272: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9845 - val_loss: 8.3333e-04 - val_r2_score: 0.9980\n",
      "Epoch 273/300\n",
      "759/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9822\n",
      "Epoch 273: val_loss improved from 0.00083 to 0.00083, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9596 - val_loss: 8.3227e-04 - val_r2_score: 0.9977\n",
      "Epoch 274/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0020 - r2_score: 0.9804\n",
      "Epoch 274: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9537 - val_loss: 8.3709e-04 - val_r2_score: 0.9931\n",
      "Epoch 275/300\n",
      "750/761 [============================>.] - ETA: 0s - loss: 0.0022 - r2_score: 0.9805\n",
      "Epoch 275: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9520 - val_loss: 8.3303e-04 - val_r2_score: 0.9933\n",
      "Epoch 276/300\n",
      "760/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9715\n",
      "Epoch 276: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9887 - val_loss: 8.3456e-04 - val_r2_score: 0.9861\n",
      "Epoch 277/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9847\n",
      "Epoch 277: val_loss improved from 0.00083 to 0.00083, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0022 - r2_score: 0.9727 - val_loss: 8.3202e-04 - val_r2_score: 0.9890\n",
      "Epoch 278/300\n",
      "756/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9908\n",
      "Epoch 278: val_loss improved from 0.00083 to 0.00083, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9763 - val_loss: 8.2981e-04 - val_r2_score: 0.9983\n",
      "Epoch 279/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9488\n",
      "Epoch 279: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9728 - val_loss: 8.3071e-04 - val_r2_score: 0.9914\n",
      "Epoch 280/300\n",
      "759/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9843\n",
      "Epoch 280: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9366 - val_loss: 8.3093e-04 - val_r2_score: 0.9991\n",
      "Epoch 281/300\n",
      "757/761 [============================>.] - ETA: 0s - loss: 0.0020 - r2_score: 0.9891\n",
      "Epoch 281: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9578 - val_loss: 8.3431e-04 - val_r2_score: 0.9921\n",
      "Epoch 282/300\n",
      "759/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9832\n",
      "Epoch 282: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9369 - val_loss: 8.4209e-04 - val_r2_score: 0.9975\n",
      "Epoch 283/300\n",
      "756/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9685\n",
      "Epoch 283: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9788 - val_loss: 8.4328e-04 - val_r2_score: 0.9832\n",
      "Epoch 284/300\n",
      "756/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9682\n",
      "Epoch 284: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9887 - val_loss: 8.4252e-04 - val_r2_score: 0.9929\n",
      "Epoch 285/300\n",
      "756/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9528\n",
      "Epoch 285: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9692 - val_loss: 8.3601e-04 - val_r2_score: 0.9976\n",
      "Epoch 286/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9754\n",
      "Epoch 286: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9707 - val_loss: 8.3474e-04 - val_r2_score: 0.9805\n",
      "Epoch 287/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9824\n",
      "Epoch 287: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9789 - val_loss: 8.3886e-04 - val_r2_score: 0.9978\n",
      "Epoch 288/300\n",
      "757/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9756\n",
      "Epoch 288: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9713 - val_loss: 8.3170e-04 - val_r2_score: 0.9893\n",
      "Epoch 289/300\n",
      "757/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9701\n",
      "Epoch 289: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9837 - val_loss: 8.3399e-04 - val_r2_score: 0.9826\n",
      "Epoch 290/300\n",
      "761/761 [==============================] - ETA: 0s - loss: 0.0021 - r2_score: 0.9789\n",
      "Epoch 290: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9789 - val_loss: 8.3273e-04 - val_r2_score: 0.9952\n",
      "Epoch 291/300\n",
      "759/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9855\n",
      "Epoch 291: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9853 - val_loss: 8.3541e-04 - val_r2_score: 0.9699\n",
      "Epoch 292/300\n",
      "749/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9866\n",
      "Epoch 292: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9868 - val_loss: 8.3311e-04 - val_r2_score: 0.9839\n",
      "Epoch 293/300\n",
      "753/761 [============================>.] - ETA: 0s - loss: 0.0020 - r2_score: 0.9683\n",
      "Epoch 293: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0020 - r2_score: 0.9856 - val_loss: 8.3218e-04 - val_r2_score: 0.9973\n",
      "Epoch 294/300\n",
      "752/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9878\n",
      "Epoch 294: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9904 - val_loss: 8.3316e-04 - val_r2_score: 0.9836\n",
      "Epoch 295/300\n",
      "761/761 [==============================] - ETA: 0s - loss: 0.0020 - r2_score: 0.9561\n",
      "Epoch 295: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0020 - r2_score: 0.9561 - val_loss: 8.4113e-04 - val_r2_score: 0.9984\n",
      "Epoch 296/300\n",
      "760/761 [============================>.] - ETA: 0s - loss: 0.0020 - r2_score: 0.9713\n",
      "Epoch 296: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0020 - r2_score: 0.9843 - val_loss: 8.3357e-04 - val_r2_score: 0.9985\n",
      "Epoch 297/300\n",
      "754/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9484\n",
      "Epoch 297: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9358 - val_loss: 8.4155e-04 - val_r2_score: 0.9973\n",
      "Epoch 298/300\n",
      "759/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9900\n",
      "Epoch 298: val_loss improved from 0.00083 to 0.00083, saving model to bestsofar.h5\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9899 - val_loss: 8.2825e-04 - val_r2_score: 0.9966\n",
      "Epoch 299/300\n",
      "759/761 [============================>.] - ETA: 0s - loss: 0.0021 - r2_score: 0.9762\n",
      "Epoch 299: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9924 - val_loss: 8.3150e-04 - val_r2_score: 0.9907\n",
      "Epoch 300/300\n",
      "761/761 [==============================] - ETA: 0s - loss: 0.0021 - r2_score: 0.9719\n",
      "Epoch 300: val_loss did not improve from 0.00083\n",
      "761/761 [==============================] - 4s 4ms/step - loss: 0.0021 - r2_score: 0.9719 - val_loss: 8.3210e-04 - val_r2_score: 0.9957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f8330194250>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset_train,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          validation_data=dataset_vali,\n",
    "          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "134c23c8-62e8-4c16-910b-ec069da85551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               5632      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 512)               2048      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 160)               20640     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 322       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 356962 (1.36 MB)\n",
      "Trainable params: 355938 (1.36 MB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2af1b663-5d00-47bb-b5db-4d1609615afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('bestsofar.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e76e5fb-2636-4d29-bd74-157b145d2375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/delta/miniconda3/envs/jt_ma/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('fullfreq25-65_surogate.h5', include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75159cd3-1f42-442b-b96c-3fa4d258aef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
