{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f008c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3776b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices(device_type = 'GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87ed31bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self):\n",
    "        AS_dataset = pd.read_csv('./Arbitrary_Single_band_Coupler_Phase_Shift.csv', encoding='utf-8')\n",
    "        self.X = AS_dataset.loc[:,'freq':'L4'].to_numpy()\n",
    "        self.y = AS_dataset.loc[:,'S11r':'S41i'].to_numpy()\n",
    "#         self.mmX = MinMaxScaler()\n",
    "#         self.X[:,1:] = self.mmX.fit_transform(self.X[:,1:])\n",
    "#         self.X[:,0] = self.X[:,0] / 10\n",
    "#         self.X, _, self.y, _ = train_test_split(self.X, self.y, test_size=0.75, random_state=0)\n",
    "        self.X_train, self.X_vali, self.y_train, self.y_vali = train_test_split(self.X, self.y, test_size=0.1, random_state=0)\n",
    "        self.num_train = self.X_train.shape[0]\n",
    "    def get_batch(self, batch_size=0, mode='train'):\n",
    "        if mode == 'train':\n",
    "            index = np.random.randint(0, self.num_train, batch_size)\n",
    "            return self.X_train[index], self.y_train[index]\n",
    "        if mode == 'validate':\n",
    "            return self.X_vali, self.y_vali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4d306be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(units=512, activation=tf.nn.leaky_relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(units=1024, activation=tf.nn.leaky_relu)\n",
    "        self.dense3 = tf.keras.layers.Dense(units=512, activation=tf.nn.leaky_relu)\n",
    "        self.dense4 = tf.keras.layers.Dense(units=256, activation=tf.nn.leaky_relu)\n",
    "        self.dense5 = tf.keras.layers.Dense(units=8)\n",
    "    \n",
    "#     @tf.function\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dense4(x)\n",
    "        output = self.dense5(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2213fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "batch_size = 1024\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "282c7cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "data_loader = DataLoader()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "X_v, y_v = data_loader.get_batch(mode='validate')\n",
    "def train():\n",
    "    num_batch = data_loader.num_train // batch_size\n",
    "    for epoch_index in range(num_epochs):\n",
    "        for batch in range(num_batch):\n",
    "            X, y = data_loader.get_batch(batch_size)\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = model(X)\n",
    "                tr_mse = tf.reduce_mean(tf.square(y_pred - y))\n",
    "            grads = tape.gradient(tr_mse, model.variables)\n",
    "            optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
    "        if epoch_index % 10 == 0 or epoch_index == num_epochs - 1:\n",
    "            tr_rmse = tf.sqrt(tr_mse)\n",
    "            tr_mae = tf.reduce_mean(tf.abs(y_pred - y))\n",
    "            tr_r2 = 1 - tf.reduce_sum(tf.square(y_pred - y)) / tf.reduce_sum(tf.square(y - tf.cast(tf.reduce_mean(y), dtype=tf.float32)))\n",
    "            print(\"epoch:{}\".format(epoch_index))\n",
    "            print(\"train mse:{} rmse:{} mae:{} r2:{}\".format(tr_mse, tr_rmse, tr_mae, tr_r2))\n",
    "            y_v_p = model(X_v)\n",
    "            va_mse = tf.reduce_mean(tf.square(y_v_p - y_v))\n",
    "            va_rmse = tf.sqrt(va_mse)\n",
    "            va_mae = tf.reduce_mean(tf.abs(y_v_p - y_v))\n",
    "            va_r2 = 1 - tf.reduce_sum(tf.square(y_v_p - y_v)) / tf.reduce_sum(tf.square(y_v - tf.cast(tf.reduce_mean(y_v), dtype=tf.float32)))\n",
    "            print(\"vali mse:{} rmse:{} mae:{} r2:{}\".format(va_mse, va_rmse, va_mae, va_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0897444",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "train mse:0.0952557697892189 rmse:0.30863532423973083 mae:0.25238871574401855 r2:0.21212852001190186\n",
      "vali mse:0.09371825307607651 rmse:0.3061343729496002 mae:0.24976204335689545 r2:0.22309726476669312\n",
      "epoch:10\n",
      "train mse:0.07130761444568634 rmse:0.2670348584651947 mae:0.21519824862480164 r2:0.40854591131210327\n",
      "vali mse:0.07203582674264908 rmse:0.26839491724967957 mae:0.21656323969364166 r2:0.4028396010398865\n",
      "epoch:20\n",
      "train mse:0.06365450471639633 rmse:0.2522984445095062 mae:0.20191535353660583 r2:0.47458916902542114\n",
      "vali mse:0.06593257933855057 rmse:0.2567733824253082 mae:0.2049683779478073 r2:0.4534341096878052\n",
      "epoch:30\n",
      "train mse:0.061959683895111084 rmse:0.24891701340675354 mae:0.19569209218025208 r2:0.4868156909942627\n",
      "vali mse:0.05900618061423302 rmse:0.24291187524795532 mae:0.19354911148548126 r2:0.5108523368835449\n",
      "epoch:40\n",
      "train mse:0.05336909368634224 rmse:0.23101751506328583 mae:0.1824861466884613 r2:0.5586906671524048\n",
      "vali mse:0.05311031639575958 rmse:0.23045675456523895 mae:0.18116815388202667 r2:0.5597277283668518\n",
      "epoch:50\n",
      "train mse:0.04586613178253174 rmse:0.21416379511356354 mae:0.16814455389976501 r2:0.6204397082328796\n",
      "vali mse:0.046283621340990067 rmse:0.21513628959655762 mae:0.16979657113552094 r2:0.6163194179534912\n",
      "epoch:60\n",
      "train mse:0.041858404874801636 rmse:0.20459327101707458 mae:0.16010242700576782 r2:0.653602659702301\n",
      "vali mse:0.04241219162940979 rmse:0.20594221353530884 mae:0.16273878514766693 r2:0.6484127044677734\n",
      "epoch:70\n",
      "train mse:0.041226260364055634 rmse:0.20304250717163086 mae:0.157755047082901 r2:0.6574360132217407\n",
      "vali mse:0.04030068591237068 rmse:0.20075030624866486 mae:0.15804699063301086 r2:0.6659165620803833\n",
      "epoch:80\n",
      "train mse:0.03974876552820206 rmse:0.19937092065811157 mae:0.15642209351062775 r2:0.6701278686523438\n",
      "vali mse:0.0384436696767807 rmse:0.1960705667734146 mae:0.1523059755563736 r2:0.6813108325004578\n",
      "epoch:90\n",
      "train mse:0.034879766404628754 rmse:0.1867612600326538 mae:0.14436118304729462 r2:0.711640477180481\n",
      "vali mse:0.03781593218445778 rmse:0.19446319341659546 mae:0.15237879753112793 r2:0.6865146160125732\n",
      "epoch:100\n",
      "train mse:0.03455635532736778 rmse:0.18589340150356293 mae:0.14423778653144836 r2:0.7146183252334595\n",
      "vali mse:0.03475450724363327 rmse:0.1864255964756012 mae:0.1453680396080017 r2:0.7118931412696838\n",
      "epoch:110\n",
      "train mse:0.035857006907463074 rmse:0.18935945630073547 mae:0.14598578214645386 r2:0.7034059762954712\n",
      "vali mse:0.03563176840543747 rmse:0.1887637972831726 mae:0.14720530807971954 r2:0.7046208381652832\n",
      "epoch:120\n",
      "train mse:0.03450543060898781 rmse:0.1857563704252243 mae:0.14209115505218506 r2:0.7148398756980896\n",
      "vali mse:0.0337701253592968 rmse:0.18376649916172028 mae:0.1422642022371292 r2:0.7200534343719482\n",
      "epoch:130\n",
      "train mse:0.029244475066661835 rmse:0.17101015150547028 mae:0.13162733614444733 r2:0.7583921551704407\n",
      "vali mse:0.029899567365646362 rmse:0.17291490733623505 mae:0.1339017152786255 r2:0.7521394491195679\n",
      "epoch:140\n",
      "train mse:0.028892245143651962 rmse:0.16997718811035156 mae:0.130789116024971 r2:0.7611491680145264\n",
      "vali mse:0.028690548613667488 rmse:0.16938284039497375 mae:0.12984143197536469 r2:0.7621619701385498\n",
      "epoch:150\n",
      "train mse:0.024707838892936707 rmse:0.15718726813793182 mae:0.1209574043750763 r2:0.7955916523933411\n",
      "vali mse:0.027335496619343758 rmse:0.16533450782299042 mae:0.12537334859371185 r2:0.7733950614929199\n",
      "epoch:160\n",
      "train mse:0.025729432702064514 rmse:0.16040396690368652 mae:0.12134552001953125 r2:0.7864571809768677\n",
      "vali mse:0.02586814947426319 rmse:0.16083578765392303 mae:0.12164393812417984 r2:0.7855589985847473\n",
      "epoch:170\n",
      "train mse:0.019430186599493027 rmse:0.1393921971321106 mae:0.10476270318031311 r2:0.8385096788406372\n",
      "vali mse:0.022265244275331497 rmse:0.149215430021286 mae:0.11328653991222382 r2:0.815426230430603\n",
      "epoch:180\n",
      "train mse:0.019362371414899826 rmse:0.1391487419605255 mae:0.10479827225208282 r2:0.8394378423690796\n",
      "vali mse:0.022043291479349136 rmse:0.14846983551979065 mae:0.11089559644460678 r2:0.8172662258148193\n",
      "epoch:190\n",
      "train mse:0.022514168173074722 rmse:0.1500472128391266 mae:0.11229294538497925 r2:0.8134972453117371\n",
      "vali mse:0.02281823195517063 rmse:0.15105704963207245 mae:0.1138250008225441 r2:0.8108420968055725\n",
      "epoch:199\n",
      "train mse:0.01407872885465622 rmse:0.11865381896495819 mae:0.08949249982833862 r2:0.883340060710907\n",
      "vali mse:0.01652388833463192 rmse:0.12854528427124023 mae:0.09633903205394745 r2:0.8630207777023315\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0279a086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, './models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b733364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.saved_model.load('./models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f4c0748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_func(s_para):\n",
    "    E = tf.square(s_para)\n",
    "    E11 = E[:,0] + E[:,1]\n",
    "    E21 = E[:,2] + E[:,3]\n",
    "    E31 = E[:,4] + E[:,5]\n",
    "    E41 = E[:,6] + E[:,7]\n",
    "    l1 = E11 - E21 - E31 + E41\n",
    "    l2 = tf.square(E21 / (E31 + E21) - 2 / 3)\n",
    "    l3 = tf.square(tf.math.atan2(s_para[:,5], s_para[:,4]) - tf.math.atan2(s_para[:,3], s_para[:,2]) - np.pi / 4)\n",
    "    l4 = tf.square(tf.reduce_sum(E, axis=1) - 1)\n",
    "    loss = l1 + l2 + l3 + l4\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66b3fff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 5000\n",
    "num_node_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "781053c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.01)\n",
    "\n",
    "mmin = np.min(data_loader.X[: , 1: ], axis=0)\n",
    "mmax = np.max(data_loader.X[: , 1: ], axis=0)\n",
    "\n",
    "# structure.append(tf.Variable(np.random.uniform(0, 1, (num_nodes, 10)), dtype=tf.float32))\n",
    "structure = tf.Variable(np.random.uniform(mmin, mmax, (num_nodes, 12)), dtype=tf.float32)\n",
    "\n",
    "freq1 = tf.ones([num_nodes, 1]) * 2.4\n",
    "freq2 = tf.ones([num_nodes, 1]) * 2.5\n",
    "freq3 = tf.ones([num_nodes, 1]) * 2.6\n",
    "\n",
    "minLoss = 0\n",
    "minIndex = 0\n",
    "minS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "72925434",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestLoss = 10\n",
    "bestStructure = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0848ef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(structure):\n",
    "    inva_place1 = tf.where(tf.logical_or(structure[:,:8] < 1, structure[:,:8] > 4))\n",
    "    structure = tf.tensor_scatter_nd_update(structure, [inva_place1], [np.random.uniform(mmin[inva_place1[:,1]], mmax[inva_place1[:,1]], (inva_place1.shape[0]))])\n",
    "    \n",
    "    inva_place2 = tf.where(tf.logical_or(structure[:,8:] < 4, structure[:,8:] > 100)) + [0, 8]\n",
    "    structure = tf.tensor_scatter_nd_update(structure, [inva_place2], [np.random.uniform(mmin[inva_place2[:,1]], mmax[inva_place2[:,1]], (inva_place2.shape[0]))])\n",
    "    \n",
    "    return tf.Variable(structure)\n",
    "    \n",
    "    # structure[j] = tf.Variable(tf.tensor_scatter_nd_update(structure[j], [nega_place], [np.random.uniform(0, 1, (nega_place.shape[0]))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19fbd168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(structure):\n",
    "    inva_place1 = tf.where(tf.logical_or(structure[:,:8] < 0, structure[:,:8] > 10))\n",
    "    structure = tf.tensor_scatter_nd_update(structure, [inva_place1], [np.random.uniform(mmin[inva_place1[:,1]], mmax[inva_place1[:,1]], (inva_place1.shape[0]))])\n",
    "    \n",
    "    inva_place2 = tf.where(tf.logical_or(structure[:,8:] < 1, structure[:,8:] > 100)) + [0, 8]\n",
    "    structure = tf.tensor_scatter_nd_update(structure, [inva_place2], [np.random.uniform(mmin[inva_place2[:,1]], mmax[inva_place2[:,1]], (inva_place2.shape[0]))])\n",
    "    \n",
    "    inva_place3 = tf.where(structure[:,1] < structure[:,7]) # W2 < W8\n",
    "    a = tf.concat([inva_place3, tf.ones([inva_place3.shape[0], 1], dtype=tf.int64)], axis=1)\n",
    "    b = tf.concat([inva_place3, tf.ones([inva_place3.shape[0], 1], dtype=tf.int64) * 7], axis=1)\n",
    "    ori = tf.concat([a, b], axis=0)\n",
    "    cht = tf.concat([b, a], axis=0)\n",
    "    structure = tf.tensor_scatter_nd_update(structure, [ori], [tf.gather_nd(structure, cht)])\n",
    "    \n",
    "    inva_place4 = tf.where(structure[:,1] < structure[:,0]) # W2 < W1\n",
    "    a = tf.concat([inva_place4, tf.ones([inva_place4.shape[0], 1], dtype=tf.int64)], axis=1)\n",
    "    b = tf.concat([inva_place4, tf.zeros([inva_place4.shape[0], 1], dtype=tf.int64)], axis=1)\n",
    "    ori = tf.concat([a, b], axis=0)\n",
    "    cht = tf.concat([b, a], axis=0)\n",
    "    structure = tf.tensor_scatter_nd_update(structure, [ori], [tf.gather_nd(structure, cht)])\n",
    "    \n",
    "    inva_place5 = tf.where(structure[:,4] < structure[:,3]) # W5 < W4\n",
    "    a = tf.concat([inva_place5, tf.ones([inva_place5.shape[0], 1], dtype=tf.int64) * 4], axis=1)\n",
    "    b = tf.concat([inva_place5, tf.ones([inva_place5.shape[0], 1], dtype=tf.int64) * 3], axis=1)\n",
    "    ori = tf.concat([a, b], axis=0)\n",
    "    cht = tf.concat([b, a], axis=0)\n",
    "    structure = tf.tensor_scatter_nd_update(structure, [ori], [tf.gather_nd(structure, cht)])\n",
    "    \n",
    "    inva_place6 = tf.where(structure[:,4] < structure[:,5]) # W5 < W6\n",
    "    a = tf.concat([inva_place6, tf.ones([inva_place6.shape[0], 1], dtype=tf.int64) * 4], axis=1)\n",
    "    b = tf.concat([inva_place6, tf.ones([inva_place6.shape[0], 1], dtype=tf.int64) * 5], axis=1)\n",
    "    ori = tf.concat([a, b], axis=0)\n",
    "    cht = tf.concat([b, a], axis=0)\n",
    "    structure = tf.tensor_scatter_nd_update(structure, [ori], [tf.gather_nd(structure, cht)])\n",
    "    \n",
    "    return tf.Variable(structure)\n",
    "    \n",
    "    # structure[j] = tf.Variable(tf.tensor_scatter_nd_update(structure[j], [nega_place], [np.random.uniform(0, 1, (nega_place.shape[0]))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aeaa40d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.4841418\n",
      "2702\n",
      "0 -1.4841418\n",
      "[ 1.205315   3.2317932  1.0367705  1.3162541  1.9051796  3.4026542\n",
      "  1.0180898  4.46279   95.0443    61.16179   57.827282  21.524893 ]\n",
      "\n",
      "-1.3353468\n",
      "-1.3470559\n",
      "-1.0160162\n",
      "-1.0303379\n",
      "-1.0438588\n",
      "-1.0569081\n",
      "-1.0695128\n",
      "-1.08178\n",
      "-1.0938578\n",
      "-1.105901\n",
      "-1.1179302\n",
      "-1.1298566\n",
      "-1.1417377\n",
      "-1.1536366\n",
      "-1.1654986\n",
      "-1.1773059\n",
      "-1.1889197\n",
      "-1.2005298\n",
      "-1.2121832\n",
      "-1.2237055\n",
      "-1.2351315\n",
      "-1.2466139\n",
      "-1.258227\n",
      "-1.2699912\n",
      "-1.2818677\n",
      "-1.2939782\n",
      "-1.306139\n",
      "-1.3186135\n",
      "-1.3313334\n",
      "-1.3441751\n",
      "-1.3571861\n",
      "-1.3704666\n",
      "-1.3837154\n",
      "-1.397099\n",
      "-1.410603\n",
      "-1.4243273\n",
      "-1.4382206\n",
      "-1.4522957\n",
      "-1.4667287\n",
      "-1.1817831\n",
      "-1.1960119\n",
      "-1.2103151\n",
      "-1.2247276\n",
      "-1.1407487\n",
      "-1.1507926\n",
      "-1.1608348\n",
      "-1.1709821\n",
      "-1.1811669\n",
      "-1.1915586\n",
      "-1.2019892\n",
      "-1.2188542\n",
      "-1.2263175\n",
      "-1.2369691\n",
      "-1.2524076\n",
      "-1.2680229\n",
      "-1.2840406\n",
      "-1.300142\n",
      "-1.3167752\n",
      "-1.3334457\n",
      "-1.3493904\n",
      "-1.365767\n",
      "-1.382197\n",
      "-1.3990701\n",
      "-1.4161077\n",
      "-1.4331266\n",
      "-1.4500605\n",
      "-1.4666924\n",
      "-1.4835145\n",
      "-1.5004816\n",
      "3730\n",
      "69 -1.5004816\n",
      "[ 3.075873   3.0864484  1.4453377  2.2318661  2.5851016  3.7604563\n",
      "  1.4234874  3.4824576  8.731785  20.503504  52.980404  65.05521  ]\n",
      "\n",
      "-1.5178535\n",
      "3730\n",
      "70 -1.5178535\n",
      "[ 3.0841022  3.094678   1.4371083  2.2236383  2.5933309  3.7686849\n",
      "  1.4152583  3.490686   8.740014  20.495275  52.988632  65.06344  ]\n",
      "\n",
      "-1.5353422\n",
      "3730\n",
      "71 -1.5353422\n",
      "[ 3.0923874  3.1029632  1.4288229  2.2153542  2.6016161  3.7769694\n",
      "  1.4069731  3.4989703  8.7483    20.486992  52.996918  65.071724 ]\n",
      "\n",
      "-1.5531044\n",
      "3730\n",
      "72 -1.5531044\n",
      "[ 3.1007283  3.1113043  1.4204818  2.2070143  2.6099572  3.7853096\n",
      "  1.3986324  3.5073104  8.75664   20.478653  53.005257  65.08006  ]\n",
      "\n",
      "-1.5705421\n",
      "3730\n",
      "73 -1.5705421\n",
      "[ 3.1091244  3.1197004  1.4120855  2.1986194  2.6183534  3.793705\n",
      "  1.3902364  3.5157058  8.765037  20.470259  53.013653  65.088455 ]\n",
      "\n",
      "-1.5878092\n",
      "3730\n",
      "74 -1.5878092\n",
      "[ 3.1175754  3.1281514  1.4036344  2.1901696  2.6268044  3.8021553\n",
      "  1.3817855  3.5241559  8.773487  20.46181   53.022102  65.09691  ]\n",
      "\n",
      "-1.6053193\n",
      "3730\n",
      "75 -1.6053193\n",
      "[ 3.1260808  3.136657   1.3951288  2.1816652  2.63531    3.8106601\n",
      "  1.3732803  3.5326602  8.781992  20.453304  53.03061   65.105415 ]\n",
      "\n",
      "-1.6231458\n",
      "3730\n",
      "76 -1.6231458\n",
      "[ 3.1346402  3.1452167  1.3865693  2.173107   2.6438694  3.819219\n",
      "  1.364721   3.541219   8.790551  20.444746  53.03917   65.113976 ]\n",
      "\n",
      "-1.6410768\n",
      "3730\n",
      "77 -1.6410768\n",
      "[ 3.1432533  3.15383    1.3779559  2.1644948  2.6524827  3.8278317\n",
      "  1.3561078  3.5498314  8.799165  20.436134  53.047783  65.12259  ]\n",
      "\n",
      "-1.6591728\n",
      "3730\n",
      "78 -1.6591728\n",
      "[ 3.1519198  3.1624968  1.3692892  2.1558294  2.6611495  3.8364978\n",
      "  1.3474413  3.5584972  8.807831  20.42747   53.05645   65.131256 ]\n",
      "\n",
      "-1.6773386\n",
      "3730\n",
      "79 -1.6773386\n",
      "[ 3.1606393  3.1712165  1.3605695  2.1471112  2.6698692  3.8452168\n",
      "  1.3387219  3.567216   8.81655   20.41875   53.06517   65.13998  ]\n",
      "\n",
      "-1.6954896\n",
      "3730\n",
      "80 -1.6954896\n",
      "[ 3.1694114  3.1799889  1.3517971  2.1383402  2.6786416  3.8539884\n",
      "  1.3299499  3.575987   8.825322  20.409979  53.073944  65.14875  ]\n",
      "\n",
      "-1.7138416\n",
      "3730\n",
      "81 -1.7138416\n",
      "[ 3.1782358  3.1888134  1.3429725  2.129517   2.6874661  3.8628123\n",
      "  1.3211255  3.5848107  8.8341465 20.401155  53.082767  65.15758  ]\n",
      "\n",
      "-1.7326492\n",
      "3730\n",
      "82 -1.7326492\n",
      "[ 3.187112   3.19769    1.334096   2.1206422  2.6963427  3.8716884\n",
      "  1.3122492  3.5936863  8.843023  20.392279  53.091644  65.16645  ]\n",
      "\n",
      "-1.7519481\n",
      "3730\n",
      "83 -1.7519481\n",
      "[ 3.1960402  3.206618   1.3251678  2.1117156  2.7052708  3.880616\n",
      "  1.3033214  3.6026137  8.851952  20.38335   53.10057   65.17538  ]\n",
      "\n",
      "-1.7715718\n",
      "3730\n",
      "84 -1.7715718\n",
      "[ 3.2050195  3.2155974  1.3161883  2.1027377  2.71425    3.8895948\n",
      "  1.2943422  3.6115923  8.86093   20.37437   53.10955   65.18436  ]\n",
      "\n",
      "-1.791234\n",
      "3730\n",
      "85 -1.791234\n",
      "[ 3.2140496  3.2246277  1.307158   2.0937088  2.7232804  3.8986244\n",
      "  1.285312   3.620622   8.869961  20.365341  53.11858   65.19339  ]\n",
      "\n",
      "-1.8102381\n",
      "3730\n",
      "86 -1.8102381\n",
      "[ 3.2231305  3.2337086  1.298077   2.0846293  2.7323613  3.9077048\n",
      "  1.2762313  3.629702   8.879042  20.35626   53.12766   65.20247  ]\n",
      "\n",
      "-1.8291256\n",
      "3730\n",
      "87 -1.8291256\n",
      "[ 3.2322614  3.2428398  1.2889458  2.0754995  2.7414925  3.9168355\n",
      "  1.2671003  3.638832   8.888173  20.34713   53.13679   65.2116   ]\n",
      "\n",
      "-1.8478513\n",
      "3730\n",
      "88 -1.8478513\n",
      "[ 3.2414424  3.252021   1.2797645  2.0663197  2.7506738  3.9260163\n",
      "  1.2579194  3.6480122  8.897354  20.33795   53.145973  65.22078  ]\n",
      "\n",
      "-1.8665621\n",
      "3730\n",
      "89 -1.8665621\n",
      "[ 3.250673   3.261252   1.2705337  2.0570903  2.7599046  3.9352467\n",
      "  1.2486888  3.657242   8.906585  20.32872   53.155205  65.23001  ]\n",
      "\n",
      "-1.8852221\n",
      "3730\n",
      "90 -1.8852221\n",
      "[ 3.259953   3.2705321  1.2612535  2.0478115  2.7691848  3.9445264\n",
      "  1.2394089  3.6665213  8.915865  20.31944   53.164486  65.23929  ]\n",
      "\n",
      "-1.903755\n",
      "3730\n",
      "91 -1.903755\n",
      "[ 3.269282   3.2798615  1.2519243  2.038484   2.7785141  3.9538553\n",
      "  1.2300799  3.6758494  8.925194  20.310112  53.173817  65.24862  ]\n",
      "\n",
      "-1.9224415\n",
      "3730\n",
      "92 -1.9224415\n",
      "[ 3.2786598  3.2892394  1.2425463  2.029109   2.787892   3.9632328\n",
      "  1.2207022  3.6852267  8.934571  20.300734  53.183193  65.257996 ]\n",
      "\n",
      "-1.9417205\n",
      "3730\n",
      "93 -1.9417205\n",
      "[ 3.288086   3.2986658  1.2331198  2.0196867  2.7973185  3.9726586\n",
      "  1.2112759  3.6946523  8.943997  20.291307  53.19262   65.26742  ]\n",
      "\n",
      "-1.9617934\n",
      "3730\n",
      "94 -1.9617934\n",
      "[ 3.2975602  3.3081403  1.2236452  2.0102181  2.806793   3.9821327\n",
      "  1.2018015  3.7041261  8.953472  20.281834  53.202095  65.27689  ]\n",
      "\n",
      "-1.9823011\n",
      "3730\n",
      "95 -1.9823011\n",
      "[ 3.3070824  3.3176627  1.2141228  2.000699   2.8163154  3.9916546\n",
      "  1.1922792  3.7136478  8.962995  20.272312  53.211617  65.286415 ]\n",
      "\n",
      "-1.9143395\n",
      "-1.9332333\n",
      "-1.9519713\n",
      "-1.9706213\n",
      "-1.9890769\n",
      "3730\n",
      "100 -1.9890769\n",
      "[ 3.3554022  3.3659835  1.1658021  2.0298781  2.8646357  2.6027505\n",
      "  1.2214557  3.761965   9.011314  20.223993  53.259937  65.33474  ]\n",
      "\n",
      "-2.0080583\n",
      "3730\n",
      "101 -2.0080583\n",
      "[ 3.365206   3.3757873  1.1559982  2.0396783  2.8744395  2.6125538\n",
      "  1.2116534  3.7717683  9.021118  20.21419   53.26974   65.34454  ]\n",
      "\n",
      "-2.0274022\n",
      "3730\n",
      "102 -2.0274022\n",
      "[ 3.3750558  3.385637   1.1461483  2.0495243  2.8842893  2.6224031\n",
      "  1.201805   3.7816174  9.030968  20.20434   53.27959   65.35439  ]\n",
      "\n",
      "-2.047511\n",
      "3730\n",
      "103 -2.047511\n",
      "[ 3.384951   3.3955326  1.1362528  2.0594163  2.8941848  2.6322982\n",
      "  1.1919105  3.7915123  9.040863  20.194445  53.289486  65.36429  ]\n",
      "\n",
      "-2.067784\n",
      "3730\n",
      "104 -2.067784\n",
      "[ 3.394892   3.4054737  1.1263118  2.069355   2.9041257  2.6422389\n",
      "  1.1819701  3.8014526  9.050804  20.184504  53.299427  65.37423  ]\n",
      "\n",
      "-2.0881045\n",
      "3730\n",
      "105 -2.0881045\n",
      "[ 3.4048781  3.4154599  1.1163255  2.0793386  2.9141119  2.6522248\n",
      "  1.1719846  3.8114383  9.06079   20.174519  53.309414  65.38422  ]\n",
      "\n",
      "-2.1085887\n",
      "3730\n",
      "106 -2.1085887\n",
      "[ 3.4149091  3.425491   1.1062943  2.0893652  2.924143   2.6622555\n",
      "  1.1619538  3.8214688  9.070821  20.164488  53.319447  65.39425  ]\n",
      "\n",
      "-2.128798\n",
      "3730\n",
      "107 -2.128798\n",
      "[ 3.424985   3.435567   1.0962183  2.099438   2.934219   2.6723309\n",
      "  1.1518784  3.831544   9.080896  20.154413  53.32952   65.40433  ]\n",
      "\n",
      "-2.148568\n",
      "3730\n",
      "108 -2.148568\n",
      "[ 3.435105   3.4456873  1.086098   2.1095526  2.9443393  2.6824508\n",
      "  1.1417583  3.8416634  9.091017  20.144293  53.33964   65.414444 ]\n",
      "\n",
      "-2.1681068\n",
      "3730\n",
      "109 -2.1681068\n",
      "[ 3.4452696  3.4558518  1.0759333  2.1197078  2.9545038  2.6926148\n",
      "  1.1315941  3.851827   9.101181  20.134129  53.349808  65.42461  ]\n",
      "\n",
      "-2.1870203\n",
      "3730\n",
      "110 -2.1870203\n",
      "[ 3.455478   3.4660604  1.0657247  2.1299026  2.9647124  2.702823\n",
      "  1.1213859  3.8620346  9.111389  20.12392   53.360016  65.434814 ]\n",
      "\n",
      "-2.2057328\n",
      "3730\n",
      "111 -2.2057328\n",
      "[ 3.4657302  3.4763129  1.0554724  2.1196525  2.9749646  2.7130747\n",
      "  1.1111344  3.872286   9.121641  20.113668  53.37027   65.44507  ]\n",
      "\n",
      "-2.2238002\n",
      "3730\n",
      "112 -2.2238002\n",
      "[ 3.4760258  3.4866087  1.0451764  2.1093585  2.9852605  2.72337\n",
      "  1.1008395  3.8825812  9.131937  20.103373  53.380566  65.45536  ]\n",
      "\n",
      "-2.2430043\n",
      "3730\n",
      "113 -2.2430043\n",
      "[ 3.4863648  3.496948   1.0348371  2.0990212  2.9955997  2.7337086\n",
      "  1.090501   3.8929198  9.142276  20.093035  53.390903  65.4657   ]\n",
      "\n",
      "-2.2626479\n",
      "3730\n",
      "114 -2.2626479\n",
      "[ 3.496747   3.5073304  1.0244548  2.0886405  3.005982   2.7440903\n",
      "  1.0801189  3.9033012  9.1526575 20.082653  53.401287  65.47608  ]\n",
      "\n",
      "-2.2824638\n",
      "3730\n",
      "115 -2.2824638\n",
      "[ 3.507172   3.5177555  1.0140296  2.0782166  3.016407   2.7545147\n",
      "  1.0696939  3.9137256  9.163082  20.072227  53.411713  65.4865   ]\n",
      "\n",
      "-2.3021054\n",
      "3730\n",
      "116 -2.3021054\n",
      "[ 3.5176399  3.5282233  1.0035617  2.06775    3.0268748  2.7649817\n",
      "  1.0592264  3.9241927  9.17355   20.06176   53.42218   65.49697  ]\n",
      "\n",
      "-1.6777465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.6924291\n",
      "-1.7070934\n",
      "-1.722347\n",
      "-1.738199\n",
      "-1.7537837\n",
      "-1.7694862\n",
      "-1.7847754\n",
      "-1.7994347\n",
      "-1.8137431\n",
      "-1.827768\n",
      "-1.8416548\n",
      "-1.4713466\n",
      "-1.4862618\n",
      "-1.5011052\n",
      "-1.5154402\n",
      "-1.5300078\n",
      "-1.543858\n",
      "-1.5576881\n",
      "-1.5713868\n",
      "-1.5851058\n",
      "-1.5988231\n",
      "-1.6138616\n",
      "-1.6275463\n",
      "-1.6423978\n",
      "-1.6573198\n",
      "-1.6722163\n",
      "-1.6869857\n",
      "-1.7012517\n",
      "-1.7149245\n",
      "-1.7285869\n",
      "-1.7410848\n",
      "-1.7536918\n",
      "-1.7657676\n",
      "-1.7776015\n",
      "-1.7894682\n",
      "-1.8017185\n",
      "-1.8139658\n",
      "-1.8264031\n",
      "-1.8390979\n",
      "-1.8518898\n",
      "-1.8649732\n",
      "-1.878226\n",
      "-1.891434\n",
      "-1.9045186\n",
      "-1.8533909\n",
      "-1.8776517\n",
      "-1.8991663\n",
      "-1.836311\n",
      "-1.8491632\n",
      "-1.8615367\n",
      "-1.8735429\n",
      "-1.6819422\n",
      "-1.7064071\n",
      "-1.7308465\n",
      "-1.7517006\n",
      "-1.7726951\n",
      "-1.7941824\n",
      "-1.8162243\n",
      "-1.8376403\n",
      "-1.8590195\n",
      "-1.8794905\n",
      "-1.8989936\n",
      "-1.918333\n",
      "-1.9374418\n",
      "-1.9564971\n",
      "-1.9737813\n",
      "-1.9901028\n",
      "-2.0056787\n",
      "-2.0211158\n",
      "-2.035738\n",
      "-2.0505414\n",
      "-1.7305336\n",
      "-1.7394214\n",
      "-1.7482497\n",
      "-1.75708\n",
      "-1.7659535\n",
      "-1.7746615\n",
      "-1.7833548\n",
      "-1.7923049\n",
      "-1.8016782\n",
      "-1.811122\n",
      "-1.8208616\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_node_epochs):\n",
    "    with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "        tape.watch(structure)\n",
    "        y_pred1 = model(tf.concat([freq1, structure], axis=1))\n",
    "        y_pred2 = model(tf.concat([freq2, structure], axis=1))\n",
    "        y_pred3 = model(tf.concat([freq3, structure], axis=1))\n",
    "        loss = obj_func(y_pred1) + obj_func(y_pred2) + obj_func(y_pred3)\n",
    "    minLoss = tf.reduce_min(loss).numpy()\n",
    "    minIndex = tf.argmin(loss).numpy()\n",
    "    minS = structure[minIndex].numpy()\n",
    "    grads = tape.gradient(loss, structure)\n",
    "    opt.apply_gradients(grads_and_vars=zip([grads], [structure]))\n",
    "    structure = check(structure)\n",
    "    if minLoss < bestLoss:\n",
    "        bestLoss = minLoss\n",
    "        bestStructure = minS\n",
    "        # bestStructure = data_loader.mmX.inverse_transform([minS[0]])[0]\n",
    "        print(minIndex)\n",
    "        print(i, bestLoss)\n",
    "        print(bestStructure)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3808d0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
